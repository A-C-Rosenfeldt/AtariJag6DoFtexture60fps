So I feared that I cannot debug a beamtree, but now decided that I will keep numbers small by sticking to the raster.
So the edge equations use 16-bit screen coordinates, but for every vertex I use 320x200 screen resolution -- no fraction. For natural vertices this works just as with my normal sub-pixel correction rasterizer.
When two edges cross, I go along the dominant axis of one and find the crossing ordinate. This can use Bresenham on both edges.
When used for BSPs, the crossing has a side. When jaggies co-propagate I get a different crossing on the other side.
Now the reason for all this is that I need to insert splitting edges into a polygon and I need to know which vertices from the parent go into with side. So here I need the "internal" crossings.
I can compare ordinates along the dominant axis of the boundary polygon. Split once split twice and just compare this ordinate almost like scanline rendering.

This rasterized crossing can also be used for a portal renderer. I guess that portals produce quite a balanced tree on screen. First the current room splits, then the view through the portals split.

I seems to be very difficult to find a heuristics for the BSP. Sorting kinda brings up a tree internally. This n*log(n) sorting is what repelled me.
Also it seems like BSP will often be efficient. I don't know how to iterate on the previous frame in Fight4Life because fighters move so fast.
Binary trees can be balanced. Does it make sense to balance a tree after we already built it?
An edge on the border of the screen would be kinda useless indeed. I cannot insert poylgon-soup efficiently into a degenerated tree.
Degeneration means that I could just use the scanline rendering + bubble sort.
I don't even care too much about splits because I eat superfluous splits before the rasterizer and I think I do it efficiently ( some bit logic -- yeah sadly some branches).
So I only care about balance. So I choose the edge which splits all vertices in two equal groups ( greedy, I don't look down the tree for now).
So I don't have that many vertices and could compare all edges with all vertices. Somehow equal split can be calculated using a BSP.
Let us assume that I already have a BSP. Now I split it along the new edge. Sectors which are not cut just contriubte to the sum of their side.
So I can resist degeneration by stopping at some depth.
Then I start a new tree. I guess, I now have a forrest.
Finally, I merge them. Each tree offers a root splitting edge, which already has numbers stored with it about the own vertices split.
Now merging tries out one split over the other. Merging is n-log n. I take the more balanced order.
Merged trees have more depth allowance and may ingest polgons. But still, I might want to have to break.
With a forrest of trees, I merge the two largest .. or with some figure like minimal added depth in percentage.

The Forrest shows that bottom up using the scene graph is the way to go. The algorithm does not care if I merge a triangle into a BSP, or if I merge two BSPs.
Regarding degeneration, starting from a small polygon player or starting from large polygon level, cannot be that bad as accicentally starting with a polygon in the top left corner.
Tree merge does the balancing for us. So two merges are calculated at every level. As said above. Sounds expensive, but I want this. Last merger does not need this.

I use the same z-sort algorithm for scanline rendering as for beam tree. I may have a fresh formulation here:
z comparison pulls in the 32 bit or float discussion. Z between (non-intersecting) polygons can only be checked on pixels where they overlap.
I need compact code to fit into 4 kB. So maybe don't do any pre-checks or caching?
At least with a beam tree the number of checks is less than in the scanline rendering.

When merging two trees, z-occlusion applies. As with scanline rendering, I first solve xy screen space. So z comparison happens per leaf (sector).
The result may be that some cuts need to be undone. When two children show the same polygon: Parent becomes leaf with pointer to said polygon. Rinse repeat.
Sadly, I cannot evaluate this going top down, but it may come into play at lower levels. Large occluders close to the root should lock out fine detail behind them.

Old version.
Z-comparison is kinda expensive, so check transoformed z values first (we have those). Only if overlapping:
A raster independent method could use the seperating axis theorem. Yeah, it is quite trivial to come up with, but needs 32 bit MUL cross, inner (I guess that z interpolation boils down to this?).
So for one triangle take the vertices (I don't store normals of fighter animations to save RAM), inner product with all other vertices? Found an axis.
Reverse triangle (or flat polygon) roles, try again
I found more cases where triangles don't cut each other but need a different axis: Use other combinations of vertices. Like you can take two vertices from one triangle and one from the other.
This should cover all cases. I don't know a heuristic for the order in this latter part. Maybe sort by z and leve out the outer vertices first. Two cases. Maybe leave out second vertex first which is more at the border.
But actually, I don't care. Is fine grained enough. 2 cases and then the last 4. Maybe have a counter for those in statistic menu.
Do I really need 32 bit Math? I could find AABB and convert to floats relative to the center first. Later when I compare with the camera, I use the full 32 bit position of one vertex,
but 16 bit direction precision is in agreement with the rest of engine. Might want to have a switch for this.
I would be interesting to do an exhaustive search to get 4 planes which span up a tetraheader. Then I check if a box of 16bit precision fits in. Ah, we don't care for vector lenght. Only need 3 normals.
There is actually an easy way. With the given plane, expand points in axis direction and calculate a plane with safety margin. Check if it fullfils.
Ah all this smart math is slower than just doing 32 bit.

All this maths really wants me to run the blitter in parallel. Flip register banks. Even size optimized code and some crude round robin method should be faster than optimized sequential.
So interrupts and switched register banks seem to have a bug. So there is no clean solution for this? PEmu is broken? Is it my responsibility?
Or do I even want interrupts? Probably better check the blitter state somewhere in Maths where I just freed most registers so that I can use the for the interleave stuff.

not so fresh
For every polygon I check if the camera is in front or in the back (in 3d or by order of their vertices). Polygons
Ah, I wanted to avoid high precision z values in screen space, but I still need high precision. With skins and blends and ragdoll, polygons are not known upfront.
I need a cross-product for the normal and an inner product with the camera and .. When a triangle ends up with size after rasterization, then the turning order of the vertices is to be believed?
Imagine a slither with the middle vertex in the middle. Now add wobble. Rounded coordinates flip front and back all the time. Sub-pixel precision edges will not as bad. So it is in-consistent.
I need 3d. For polygon polygon comparision I just need one vertex of the other polyon. Now, what if the planes clip?
There still exist a plane of separation between both polygons, but it kinda difficult to find.
So I guess: Beamtree to the rescue. We have a sector with overlap. Ah, no sector needed. Just one pixel. I'll take the interpolated z value. Interpolation does not uses deltas here. Just a single point.
So with some luck one of the polygons has the vertex here? Did I not just round vertices? So I need the sub-pixel corrected W value, which I later use for the texture.
So I can just as well have the other corrected W value and the deltas? Then 32-bit multiply and done.

To get this running, I want fight4life and a simple room. I go to the leaves of the sce graph and compose towards the root.
Merge two trees. Alternating, start with larger area. Or try who doesn' split other polygons.
Split need to be cheap like doom floors. There on the path back to the front all column buffers are merged, but for the columns where ranges don't merge (for original Doom limtis (floor - ceiling)).

Visi planes
So the splits by the tree and by the perspective correction and the wraps probably don't match each other well and need to be managed. Also think about flat triangles and UV maps (with the wrap tucked away)!
For Doom floors the information to keep drawing on on the line ( scanline, but also works for other const-z ), better be provided on the edge.

For Visiplanes I want to use the most simple method. Beamtree nodes point into max 8 scene graph nodes for polygons.
I draw the scene graph in the second pass and follow all 8 (potential) children.
Then scanline algorithm: Sort by y. Sort by x. Draw spans.

Use cases:

A lot of polygons could sit on the other side, so there needs to be a list of links.
For construction I need double links.
ArrayList is okay because there will never be that much polygons on the other side. We already have a tree structure to take care of scale.
When a polygon is split the first time, the double link is created over that edge.
So when a polygon fragment is split again, the links are rewritten to keep order. For example the split could result in 4 fragments with 4 1:1 links. Or the split could end, and there
would be an ordered Array of links in the unsplit half.

Drawing could propagate through the beam tree. We hit a polygon and then follow all links. So for later we need to mark those leaves, or basically just delete them.
Alternatively, drawing could walk along the scene graph. The first polygon maintains a double link to this. Exactly one fragment needs to inherit this link.
This would also allow to sort by texture .. although it is pretty useless on Jaguar.
So how does floodfill work? I want to merge spans outside of the inner loop. So we draw a polygon. Then we reach the first scanline of the "open" edge. Then we trace the scanline through double links until we hit a real edge.
Here we encounter some vertices, which will tell us how many scanlines we can stick to the current edges as ultimate borders.
Disjunct fragments need to stay in the beam tree. Now we have a new data structure: Fragments with only partially processed scanlines. It may be enough to update the vertices, but it could happen that we split them
by a drawn band (DMZ). Floodfill uses a stack, which is a compact data structure. Splitting in the tree might be expensive.

Generally, a growing tree needs good memory managment. This is not like those quasi trees as in sorting algorithms, but we have real growth (and shrinkage, but dont care).
Since cache is too small anyway .. but is it? If we don't use a cache, the tree could simply alloc objects in an array and use pointers.
Our tree will never have more than 64k nodes. So we can use 16 bit pointers ( shift, offset ). So those array lists would have space for 3 links, and then one to an overflow object.
A handful of tuning parameters are enough. Like, we could use larger capacity for the array list.
Also my grow-from-both sides trick could work here.
The BSP has only one plane per node. So we don't need a vertex list per leaf. Visiplane floodfill may need multiple stacks to walk down the beam tree at multiple places. This is even worse for scene graph propagation.

B-tree code may fit into cache and the data cache also. Although the beam-tree algorithm is already quite big.
We don't delete, so code is rather simple. One thing would be that anytime not the last node gets children, but an "inner" one, we mirror the distance to the border to free memory, and throw the children into free water.
So this would lead to fragmented free space and needs a linked list? This sounds worse than a tree as in a b-tree.
So rather we have a B-tree and all its nodes are filled from left to right. Some heuristics lets "inner item" jump into a child block the fuller a block get. Not how child blocks in a b-tree really sit far away. So a long jump.

The "both sides" method would fill blocks in two directions with wrap around. We cannot copy nodes with growing double link list because I don't want to implement this b-tree code.

Thinking about "fight for life", each fighter could fill a beam tree and then we could note inside the leafs with which other leafs the overlap (double link, or links[4]).
Can I still obscure a portal? Break it down into one player, then on the other as if it was behind. Gets nasty when Z sort is not clear.


Deferred beam tree

Processing goes like:
Going from the root to the leafs roughly front to back. Again, inspired by the octree 8 nodes are sorted by z.
Then each leaf creates its beam tree from the edges (sorted by length).
Going up the tree I merge these trees. This is important to avoid spurious cuts (erarly on). Rather we chose the child which separates itself form the sibling the best.
Now going down another node in the scene graph, we may check the bounding volume against the already processed geometry. Not how we don't have an occluder here. This should be very similar to portals.
Portals have one convex polgaon as portal, our beam tree has many.
So the final polygons are not checked against the global beam tree, or are they? Maybe do this if the bounding volume was not cut. So as global cuts wander through the scenen, the details dive under it like under a breaking wave.
Move up the tree and merge by some simple heurist ( best sepration of children, balanced cut of parent).

It may be possible to declare parts of the scene graph as safe. Any overlapping boundary volume has be processed. So with compact enough code, the blitter could start.
Otherwise blitting happens when the scene graph is done. This is also easier with the visi planes.

So there would be a scene graph with bounding volume hierachy. For figter bipeds this volumes will be polyhedrons, but maybe the head gets a sphere?
In front of a portal sorting by screen space area, I go down the scene graph. This splits up the portal into regions which can be covered by none, both, or one of the scene nodes.
Of course, an uncovered region opens the portal. Checking for occlusion is still the tedious beam tree process, but without the extreme randomness of splits.
I add all leafs to the beam tree of their parent ( again sorted by scree area). This gets repeated up the scene graph.
With overlaps from two nodes of the scene graph, again the larger area wins.
So this has the effect that small details are not split by far away triangles. Frame to frame coherence is possible. Area also has frame to frame coherence.
This is the best BSP-tree heuristics I found.
Going up the scene graph, the "near and far field" of the boundary volume may make z values unimportant. Leafs in a tree just become holes or occluders. Tow leafs of the same kind merge.
Espcially, sorting by area may in some cases ( not bipeds ) place a large polygon behind a lot of small ones. So if other objects are far enough away, and the high detail head does not stick out,
we get a simple occluder.

Maybe I should emphasize slithers: circumfence times sqrt(area) ? How would I emphasize z ? Do I want to? Portals are demanding. Count overlap in scene graph.
Being in front gives factor 1+count/4 ? What if they stick in each other? Ah, partial count relative to combined depth.

I really think that this heuristics looks good on screen. I add more and more triangles, and then move them closer together.
Far a way the bounding cubes will protect my "battle sphere" space ships from cutting each other (no rouge siccors).
This is more impotant than fast math. For low enough detail, I will win against brute force.
It may be difficult to push to high polygon counts. My feeling says: Fight for life should be possible ( without the fence ).
I could indeed happen that high precision maths is slow. So it may make sense to use the DSP for this, while the GPU already paints .. yeah what does it paint?
There will be a "discovery" phase, where nothing can be painted. With frame coherence, this could be shorter.
Almost feels like both JRISC cores could better do parallel processing of non-overlapping scene nodes.


Beam tree favors occlusion culling over view frustum culling. We do this because existing games slow down when the enemy almost fills the screen.
Here the level ( background ) behind the one enemy is more culled by occlusion.
A dongeon has a lot of portals.
Ah still, with the low detail on the Jaguar, view frustum culling is more important.
This leads to a 2d beam tree (near plane is clipped). No need for floats thanks to the simple range. The cost of 32 bit multiplication make any short-cut attractive.
In 2d the shortest cut is only check occl on scanlines and pixels. 
There does not seem to be a cut-over from tree to list. At least it is not here. Actually, elsewhere I consider fat nodes in the tree
to optimize the generation of the BSP when combining multiple convex polygons.
I feel like this just fits into cache memory.
I could even accept the hardware z-buffer for small polygons.
Like everyone covering a small tirangle area renders a solid color ( a byte = ID of the polygon). For each small triangle I read the frame buffer into GPU cache.
Deferred texture mapping. Hmm, JRISC would extract spans, calculate the perspective correction for the texture and send it all to the blitter.
Hmm, quake software renderer only uses spans. Consicering the blitter, this makes sense.
But JRISC could extract spans in all 4 directions for const-z shenigans.
So it goes like 

LOAD
XOR with own ID in every byte
JZ "phrase mode"
cpy mask,r1
and IDs, r1
JNZ or so

This feels weird. I really should render high detail areas using the z-buffer. Even 4 cycles per loaded texel is faster than all that JRISC stuff I plan.

It seems that the brushes of quake really make sense. Convex bodies don't need a tree to resolve internal collisions.
So I should not build a tree. This is true for 2 and 3d. With two convex bodies separated by an axis, one edge of one of the bodies is the only splitter in a small tree.
But the moment they collide after projection, I need to catch up with my tree building? I can try to cut in a way which isolates the overlapping area.
Also I don't want real 3d collision in my demo / WIP (no dipping into water). So no cutes between polygons will lead to new edges for a tree. For z sort I can just use any pixel where polygons overlap,
or I can resolve this in 3d using an ad hoc BSP ( one of the polygons will have camera and other polygon on different sides). If this is indifferent, these polygons will not overlap after projection.  

When drawing a triangle strip, the first time faces flip, visibility needs to be started to be resolved.

For a beam tree I need to check how three edges cross after projection. Two of these edges may already form a vertex in a beam tree, another comes from a polygon , for example.
Back projection into 3d creates 3 planes which pass through the camera. We get each normal from a cross-product.
We want to know if the edges run (counter-) clockwise.
For this we need the "sign" of the enclosed volume.
But the sign of the volume spanned by the 3 normals is the same.

Texture mapping also likes an 3d approach. We ask how the camere hovers over the (infinite) texture and ray cast the texture.
Using sub-pixel precision edges, the edge-texture alignment is no worse than if we go indirectly over the edges, but we can reuse more information across parts or have less rounding due to a more direct calculation.
Also ray casting has no problem with clipping.
But on the other hand, we would need to match the texture infinite plane to the triangle plane in the static geometry .. so the indirection stays the same?
Regarding the screen borders, I could project them into world space,
or I could use some integer factor of screen resolution in camera space,
or I used normalized device cooridinates, skeewed so that I can have two axis aligned planes and two diagonale planes, both of which don't need multiplication and thus no rounding.
Do I want a special case in a portal renderer gone wild ( aka beam tree ) ?
With variable precsion the last multiplication has high cost.

Clipping happens in 3d because one vertex of an edge may be behind the camera. The typical projection matrix in openGl still allows a 3d interpretation if we don't matrix multiply with camera &* world Matrix .
To check if an edge passes inside of a corner, we calculate the volume spanned by this edge, the corner ray, and distance vector between camera and a vertex.
We can thus check one edge against all corners. But we can also check one corner against all edges of a convex polygon. So cache the bits of our mesh? We have this dependency graph for this.

The viewing frustum is special compared to other portals. Two sides only cut each other at the camera. General portals may be skewed.
The code can be sped up a little because there are only 9 "fields" where a vertex could land. But with skew this is more complicated.
Boolean CSG creates the shortest code, but cannot take advantage of the frustum properties. So lets stress portals! I would even accept a near plane. No need to die on this hill.
The cuts give us t, the cut position within the edge. Later we can use this for textures and shaders if we don't want to use the matrix inversion method.
To compare cuts, I use fractions ( aka homogenous cooridnates). The calcuation then should look like a cut between two portal faces. Then an edge either passes below or above this corner ray.
This is cross product and inner procuct. And some 45° rotation done using ADDs. Distribute everything and check if it is the same.
The niche thing with the cut is that I could store temporary values and reuse them for the texture, transformation or another comparison.
In vector languar the cut is: inner product of portal face normal with edge start position and with edge vector. Gives us nominator and denominator.
The corner is the cross product of two portal face normals. I don't see a similarity.

Cutting works on vertices, edges, and polygons. If I want to do this after transformation, yeah, I need to transform all vertices or check the graph. Matrix mul is slow on JRISC.
With cutting as first step I only transform visible vertices ( or their cuts ).
With all occlusion done by the beam tree and portals, I don't need to respect any order. Just follow the visibility-marks in the BSP-tree or portal graph.
Now applying cuts (in 3d for the vertex, delta (UV) along edge times t for texture) and transformation can run in parallel to the blitter.
Now certainly the blitter is not the bottleneck anymore. I feel like I cannot fit this into scratchpad RAM. I don't want to pull in Jerry in my prototype.
The complicated edge calcuation does not allow to call short and long spans in a trapez.
Anyway, long spans would undergo subdivision so we keep being limited by the GPU.
The nice thing about transformation is the simple nature of the matrix multiplication for rotation.
I could just let this run through a small queue for the next triangles. If the buffer is full, use the blitter to write out. No problem.
Though meshes could start from strips and triangles and then use 5bit relative indices like jumps. So I should probably not transform more than 32 vertices. This is alreaday taxing on the memory size.
Can I use LoadP with some clever structure? Maybe simply fill out this struct with x,y and u,v and intensity and call it a day. In other words: I could not load the full 16.16 fixed point values for the blitter.
This would already be two phrases! Some packing: 9.16 , 9.16 , 6.16 , 6.16, 8.8 . Still two phrases.
Looks like ( I got this from N64) it is really worth to transform for the next triangle and have markers in the mesh-stream which double phrase to delete from the cache and which to write back.
Notice how StoreP is buggy as you never know when store has finished. So double phrase write is impossible. Also the high register is shared with reads.
Even Read after Write is critical because the write value has its own register in the bridge to the system bus.
From the manual:(one internal load/store or two external loads/stores can be pending without holding up instruction flow).
Markers in the mesh should of course keep values which are used again after a short time.
Values which will be used later need to be written out as early as possible.
Now apparently we need to make sure that 2 more values are written out before this value is read back.
Regarding the high register, we could set the GPU to bus hog and Store, StoreP, check blitter, start blitter, check blitter.
What about DRAM refresh? I cannot guarantee anything. Seems like I need to stick to Store or use the blitter for batches.
So for each mesh transform all vertices which are accessed from triangles far apart in a batch. Copy to DRAM using the blitter.
Then while going over the faces, use a cache in SRAM and occasionally LoadP, Load, use (probably unpack), LoadP.
This is for the enemies in "Descent" or "Sky Hammer". The level would be a tree with markers. I can only cache like 8 vertices as I walk through the tree. I guess 50% cache misses.

JRISC is not good and jumping. And linking even costs more cycles and registers. Maybe I need cross product and inner product only once per overlay? Then the blitter loads new code, but keeps the vector routines.
The vector routines return to an address stored in a register. Or just use macros and more overlays..

I know that "Descent" checks for flatness of poylgons .. but Doom does not. I don't want to. I think with enough precision here again one glitch per hour is realistic. I don't think that the rasterizer crashes.
For edge interpolation I need to invert a 2x2 matrix. Every polygon is split into cuts with the frustum and other edges which only change one of the screen cooridinates.
The other edges between are paird. The side with spiky angles starts. The other side needs to chose either adjacent edge as partner.
On the other hand sub-pixel correction per line is not that expensive. fraction * all the deltas. Fraction sure is 16 bit. And as a correction this does not need more precision anyway.
Span interpolation already needs to divide by span length every scanline. No new division! Same quality as 2d deltas.

For perspective correction we calculate first and last vector and again need interpolation with its division. With span interpolation we may be tempted to do the perspective correction on the edge.
Accuracy is no problem because for longer spans I switch to subspans anyway. Ah, then I need code to calculate on the pixels. Seems like on the pixel is the way to fit code into memory.
Interestingly, with subspans on pixels, I would have two sides which need division anyway. I could get rid of this weird 1/2, 1/3, 1/4.
On good hardware I would align to phrases. Thanks to the bugs I could just try some adapative stuff. Near side a bit longer and far side shorter.
The repeated bulk span is given by the speed of the DIV instruction vs the speed of the blitter (and all the JRISC code).
I feel like JRISC is so slow that this results in 32px spans. So adaption is key here also. Revival of the 4 directions rasterizer! 

Normalized device cooridinates give us integer z values for a z-buffer, but beam tree does not use a buffer. Instead in each leaf we need to sort by z or even find a cutting edge for example for a ship floating in water.
Back-projected cuts between two edges of the beam tree result in a vertex and a ray to trace through the two polygons which we want to sort by z.
If all 3 rays agree on the sign, we are done. We get the vertices as cross product. The z depth of the ray can go over texture base system, with a cosine factor for comparison,
or we just formulate it as algebra based on polygon vertices: Invert a matrix using cross products. We get a value out of this, or two.
Of course there is some 3 volume sign interpretation to this. We have the beam and look at a segment from one polygon to the other. We have the cut between both planes. This tetraeder has a volume.
We sure need a base vertex of each polygon and the surface normals. The cross product of the normals give use the cut edge direction. We don't know the length.
Ah, this does not work out. Just do it algebraic, and the addition of fractions, and then look at the sign.

I think that I will allow cuts only for transparent objects like water. When cuts go through a leaf, I let the pixel shader decide about 7. Not much transparency allowed in my low performance scene anyway. Jaguar needs JRISC for transparency.
Otherwise I could probably find the cut of a cut on an edge of the beam tree by a long and tedious calculation.

I want to stop to think about tree optimization. To show the principle, I use simple geometry. I once thought that 3d looks good above 1k triangles.
Even here a totally degenerated tree does not take much time. I can keep everything in DRAM memory to pull in more precision later.
For real first generation 3d games, the count is even lower: Virtua fighter without 3d hair, stunt car racer 3d, elite.
I want to do descent. So a level where we see 100 polygons and one enemy with 20 polygons.
Or need for speed: One other car with 20 polygons and a street section with 5x20 polygons.

Triangle strips work well with beam trees because we will insert the shared edge into the beamtree.
Then at least we don't cut the next triangle.
I should sort strips front to back ( closest point of each strip ).
Backface culling cuts the strips => more to sort.
Even with a BSP tree I could go front to back and in each leaf sector I can try
to continue with the edge of the last sector and then go around.
For Z-Sort a hierachy of spheres would be great.
I still could try to go over edges ( the longest? ).
In a connected mesh .. ah so maybe I will forget some faces.
When I pop out of the hierachy I may need to clean up some leaf nodes 3 levels down.
Likewise the mesh walk is allowed to see into spheres escalating 3 levels up.
I think that objects will not be that big. Levels?

For optimization I take the longest edge. I may allow backtrack if I cut two many triangles?
In a prototype I should stick to greedy.

Why do I use spheres? Because noncompact polygons don't work well for sorting.
But pruning works the same: If edges of the BSP tree don't cut the sphere: Ignore!
If the cut, but no vertex is inside: ignore.


Clipping to viewport and portals and to merge BSP needs a division.
On the Jag with fast MUL we might want to use fraction also for compare.
Sometimes we get to close to zero. One code path would be to pull in more precision on demand:
But we had to round the factors to 16 bit. Now we need to MAC  ( AL * BH ) + ( AH * BL ) for the next 16 bit.
Highest precision max once a frame?
I think I calculated that I need three factors.
If I want planar bsp without triangulation, I also have the rotation multiplication.
I don't know how to do floats here. I want to translate and the float.
Hopefully the same exponents enter all products in the MAC.

We have to transit to pixel some time.
Due to the planned const-z shader I hesitate to use scanlines nor kd-trees.
Anyway, a polygon becomes smaller and may only cover on of our const-z directions:
horizontal, vertical, both diagonales.
Then we need to get the extreme pixels which are still covered.

A small polygon may even fall throught the cracks between the pixel centers.

When the cut between three edges as area to close to 0 with 16bit = 65000 subpixels on SD screen
of 320 px we have a high chance to be away from a pixel center after DIV.
The Jag has a config register to set options of div to get useful, large, numbers, even
32 bit maybe ( fixed point ) .. so sounds attractive.

So we don't know the order of cuts on the vertex on comparison.
We have a tree, but some edges appear as ghost in other nodes. Just add an attribute for this
linked list of ghosts in the corners.
We just use the rounded value to determine the color for the pixel.

We need to keep the straights straight.
When we merge two BSP, we need to be able to trust the comparison with parent splits.
Those splits are not allowed to be curved or tesselated in an uncontrolled way.
We know the ghosts and copy them into the result. What do we do with them?


Lets say I have a convex polygon in our BSPt and want to split it further.
Around we have a ring of : edge, vertex, edge, vertex
Additionally there can be ghosts in the vertices.
Theoretically I could have nearly parallel lines and thus ghost on an edge.
Now the split may stay clear of the vertices and the ghost ends up in only one of the children.
Otherwise the ghost can be in both. So many references to one ghost-creator.
I don't think that the ghost creator is interested in its ghosts.

#Comparison with Doom coverage buffer
Using the edge equations avoid strange jitter like the coverage buffer in Doom.
Even the comments in the visiPlane code mention that it only works well due to the fact that edges filled the coverage buffer .. and not sprites with transparency for example.

#flat polygons for architecture and machines

BSP in the scenery are described by a triangle with computed solid geometry after camera rotation.
One would think that this gives us complicted vertices,
but the BeamTree is concerned more with edges.
Edges between planes .. even more multiplications.


#B-Tree

Our Memory container is of course our beloved b-Tree. So I store the binary tree in an n-tree with
a tuned size. Over that size, b-tree nodes split. Below they merge.
A node will first compact itself following the binary tree structure in it.
We don't have sectors in RAM and pages are not well known. So nodes are not usually aligned.
They can grow to both sides until they collide with other nodes.
Then the larger node will split.
With large free regions ( I keep a sorted list ), I may want to pull in nodes from the outside,
so that they better match their position in the tree.

#Demo SceneGraph
I could use spheres, but I have trouble to use them for LoD. Somehow they introduce squared surfaces and cones.
So I could create a random tree with convex leafs ( asteroid field) and just aggregate by proxity.
The bounding volume is composed of all the faces which don't see the siblings and then
the closest two vertices of from different siblings are connected, then the next, until the volume in between is triangulized.
Inflate until nothing sticks out and the shape is convex. Simplify small faces and angles.

Splitting
Sort by longest, prefer who does not split others. I would guess that there is a natural order comming from our trees.
So we look down the tree and do a red-black tree kind of rotation to promote better splits. It is a bit like a chess game: pertube all the splits.
Thus it may make sense to run these on Jerry: Like in a chess game it tries multiple splits and then procedes with the tree.
If according to some heuristics, too many splits happen, Jerry rotates the top tree and again tries to build a BSP. 
Meanwhile, Tom goes into the depth of the tree.
The tree naturally has leaf nodes, but we may want to rasterize before we get there if the area of a node is small enough .. max width small and number of edges per scanline small.
Then we go by scanline and use the tree to pull the active nodes and sort the edges by x.
Like the floor in Doom this allows us to run the texture over all splits.
It even makes sense to instead use 8px regular splits on those spans for perspective corretion.
Feels like we should be greedy to find the complete uninterrupted span of the polygon and walk the tree for this, if necessary.
So we go down the nodes in the BSP tree and when the number of edges per scanline fits into the registers, we switch to scanline.
And we could try to add nodes (siblings or their children) into those scanline where we don't reach the limit.
Yeah maybe an extra code path for short subspans is useful: Every pixel is perspective correct and we use the blitter only to StoreP.
To have a simple shader state, texture caching makes sense. All visible mipmap levels are decompressed (multi-texture) and lit on demand.

transition to pixels

ensure a blitter span stays clear
	of
		real edges on screen
		seams in the texture atlas

For concave node on screen I could rasterize all edges using a spanline renderer.
For a concave leaf I need to sort vertics by y anyway.
maybe I can check if edges cross between vertex.y ? Hmm.
I don't want unecessary splits of the blitter run ( perspective wants them, but hey ), thus split by scanline and then the edges are only used to check
if the current span is still on top. Kinda like the merge of Doom floors.

The other way may be that the beam tree is too lazy to check for high precision in case no pixel is nearby. This may cut down on the real expensive MUL, the tail.

The typical problem will be that we have a beam tree with vertice which are no real vertices, but crossings.
Now we could check between which scanlines these cross.
If the crossing is far away from the lines, I can detect that ("worst case"(+some if you don't trust your code)).
It is still statistical. Makes not sense to do infi precision here?
Breadth first search? Try to isolate cases 3 edges and 2 edge+scanline whoever comes clear first?
I miss the synergy with rasterization. I mean, I need to isolate scanlines relative to real vertices, yeah but also for crossings.
Otherwise I need to raytrace. Rays to crossing ?? Rays can only shot left or right around an edge.
Rays can be rounded. Hence for small polygons raytracing on CPU may win.
Blitter spans don't follow naturally.
About synergy: if I start rasterizing corners of a polygon ( node ),
These scanline become the beam tree splits. Further down trees are spli into upper and lower part.
Make sure that there are not so may nodes below this ( small subtrees ) to avoid exessive splits.
Also frame to frame coherence only works with a beam tree.

When there is a group of faces all facing the camera then there is no occlusion.
I want a unified approach for LoD and perspective correction and lightning which recognizes the importance of the normal of a face.
Almost faces, aka organic, smooth surface should profit from this also.
Linear inter polation in the blitter still has to recognize the boundaries.
So I have a given beam tree from another node in the BSP which may contain occludions for this node.
But I don't use this node to split internally.

Maybe I can use this group apporach for all meshes. When I know that max 16 polygons overlap on a single scan line,
I can use scanline rendering to solve occlusion.
Rounding is allowed as long as I don't touch real boundaries of the BSP.
Of course, with gaps, I have a problem. So I need a "watertight" flag, which still depends on a normal or portals. I guess I can have portals in a BSP-tree.
Overall, this feels like it needs more code and not like common sense to allow rounding.
May still be interesting for dead end caves behind a simple portal (interface of a parent BSP node), just to show that there is no road-block.

I cannot unify trees with portals. I want a dongeon, so like with descent the level will have a portal base. A graph.
The bounding volume hierachy lives on top of this.
Unlike a pure portal renderer like descent, the portals only live in really portal like places. Just like all other games do it, I guess. Like Quake on PSX.
Thin structures like columns or spikes don't lend themselves to efficient portals.
Texture with transparent pixels is not what I want due to the fill rate problem on the Jaguar ( Jaguar does not count background pixels for me).
It is a slippery slope. Let's allow overdraw here and there ...
The better way a correct demo running with zero-overdraw and than I profile it and may relax this constraint to speed up the slowest frames. 

Another way would be to do raytracing on a low number of polygons. The ray position can be rounded to world space.
This may be needed for some cases: Enemies far away . Plants. When I don't want to do LoD.

For a minimal viable prototype I want to insert polygons into the beam tree as they come ( triangle strips). There is only one tree ( to debug).
I do not want the scanline renderer to deal with all splits because I want to utilize infinite bit precision (yeah, this is a must have for me aftera all) logic independent of the raster of pixels.
It is just so nice to solve for a signe of a number. The JRISC code looks kinda okay and maybe I can combine it with the general tree logic (at least before compilation).
So the edges of the polygon and the vertices are compared to the beam tree at high precision and all beam tree edges outside are discarded.
Then the beam tree inside the polygon is checked for difference in opacy and culled if not.

2d games can use Ocean-sort for sprites, but I do not see this here. Bounding volume hierachy with roughly front to back rendering is the only heuristics which I can accept. Yeah, maybe version 3 can keep states between frames.
Anyway, I have the feeling that performance for the simple scenes will already be okay and steady. Descent and Duke need added code for the portals, so they come later. As a kid I loved portals,
but in this project other stuff comes first. So fight for live of polygon cars on a pseude3d race track would be my examples. And then I suppose that the beam tree only eats 10% of the latency.
I hope that subpixel correction (a must for me) is also cheap. When I postpone rasterization, this is needed less often.
I would need one MUL to jump on a scanline, but would then have fixed point x values to compare for the scanline rendering.
Only texture mapping needs to round to a pixel. At least this shows why I should not look for synergy between beam tree splits and perspective correction splits.

Polygon merging can happen while the blitter already runs even in the beam tree.
I don't belive that high quality rendering code on the GPU has cycles or bytes to spare, nor that integration is as simple as scanline rendereing,
but it is nice to have the option.

For profiling it would be nice to separate occlusion and rasterization. It is kinda the opposite of blitter integration. And I don't mean mystic system bus performance,
but quite simple JRISC cycles. The beam tree is still the way to scale. Scanlines and grids all feel even more ugly than a bad BSP (of course profiling allows us to compare these).
Then we spit out a data structure: PolygonID, Polygons, which overlap and are in front. I could have a second list with polygons sticking (through a water surface).
I once aimed at 1000 polygons in total, but then there is also fight for live: 2 players, 2 arms, arms and legs, arm is a box of 4. So 5 bits to address any polygon.
The worst case of visible, but overlapping polygons 1000x1000 does eat up all RAM, while 256 poylgons fit into 64k.
This worst case show that we need a fall back. But detection is too late and the frame would freeze.
It is more like in production the beam tree will overlap and just stop at a certain depth. I could restart the frame with pure z-buffer.

##rasterization and fusion of spans for the blitter

The rasterizer would take all transformed vertices of all occluder polygons and the current poylgon and run the scanline algorithm over them.
The triangle set-up for a single triangle always looked like a degenerate case. So we allow polygons, but also are happy about good old quicksort (from DRAM for the higher nodes).
Ah, I always have to think of the average case. In the worst case, the beam tree wins over this occluder approach.
So anyway, per scanline we sort by x. Then we need to go over this list (even outside of the current polygon) and count up for left edges and down for right edges.
When we reach zero .. ah wait. Lets invert the edges of the current polygon and start with 1. Then when we reach zero, we start a span. Any next x will end this subspan. We stop at the right edege of the current polygon.

A polygon would only have two edges, which we would keep in the registers. The worst case of occluders is to huge that we need those edges in DRAM. Like LoadP Accumulator, Delta. Store Accumulator.
I could check for accumulator values close to zero. This exception would summon the infinite precision sub-routine and check the accumualtor and may change delta and accumulator (start value)
and mark this edge as checked (set deviation to zero). So it is guaranteed that the rounded values draw the excat same line as the infinite values with upper left rule for zero.

If I want to split up a polygon in squares for perspective correction, I could do this after rasterization. Ah no somehow this wrecks havoc on data structures.
The exception needs to occur in the beam tree when a leaf has a large area. It is very expensive to optimize the grid offset; so rather stick with a fixed grid.
I guess we got us another pass. Can we have a whole screen buffer? Then rasterize into this. 4 Lines would go into one tile row. First line with full tile set a tile to active.
Any of the 3 following lines without a full 4 decativate. Stuff needs to sit in a register to be fast. Sadly, JRISC does not have broken bitscan, but we can work around it.
Or we stick to RORQ which sets a lot of flags! A beam tree would need to work with a BSP. So the tile grid becomes a quadtree and we merge them by node area.

With fusion of the scanlines, optimization of the Beam tree is not that important anymore. We remove funny cuts which shot over from a land far far away.
Any sorting and heuristics costs time. Espcially, z-sort feels out of place. Indeed ocean sort (as for sprites on C64) might be the best solution even if it does not work for stills:
In the final frame sort by edge length visible on screen. Dominating edges shoud be promoted in the tree. Mix it with good balance (like when at a node, check that the next edge in question balances the child vertex count).
Most important for us is to know what is visble. Fusion of the next polygon can happen while we feed the blitter for the current one. I also wager that it will saturate the GPU.
We don't cache anything because we need scratch pad for code when we do two things at the same time. We don't need z-sort. So Doom like pixel mode DRAM to DRAM.
Just we should find relief in the fact that fill rate will already not be the bottleneck. Rather setting registers in the blitter all the time + subpixel edges + the span fusion will be.
How do I avoid interrupts while fusing spans? We don't have JSR. I really hope that interrupts work. Otherwise there will be idle time, just not too many superfluous register updates.
So I draw individual polygons using the scanline algorithm and an edge list. The BPS part only fuses splits as long as all vertices fit into our scratchpad buffer.

I wonder if subpixel correction and edge calcuation is already enough to keep the GPU busy while the blitter works -- even in pixel mode. Just interpolate U and V . Shading is for the full polygon as in Skyhammer.
Yeah, or shading for scanlines? But that looks so inconsistent. Here Atari is right. We either have smooth surfaces like faces or arms and legs, or we have flat textured surfaces.
Smooth surfaces need some optimization where I try to find a large group of them all showing us their front face. So there can be no internal occlusion. So this is a different rendering path loaded in scratchpad RAM later.
Code would again look ugly if the triangle set-up would be interleaved with the edge calculation of the previous polygon.
The thing is that persepective correction ( and wrap around as in Doom ) can occupy the GPU even for longer spans. I really need to identify those wide polygon bellies with small delta-z, draw them first and do some other calculations in the background.
Ah, this really looks like I should first optimize the sequential code, perhaps even go full sub-pixel correct, near z 8 directions, sub span and then record how of the blitter is not finished and how much scratch-pad is left.
Even interleaving inside a polygon needs to check for so many special cases. Like how many scanlines above the middle vertex, how many below. Additional y due to clipping? And then comes fusion of splits.
So again: The optimization can only work when I identify huge waists in the beamtree step. Probably, together with long edges, these waist need to bubble up the tree.
So width first traversal of the tree would first be interlaced, but at a certain depth be self containted, and even further down use the precalculated (triangle set-up?) values from the beginning and only draw affine trianles ( clipping is not allowe do increase the number of edges).

I need to find the relevant scanlines.
for each scan line I try to set a blitter line on the screen ( longest possible span and I may even be allowed to round the ray directions in world space),
but also in the projected space on the texture atlas with the given rounding in the blitter registers.
Anyway, I need 2 paases:
1) create beam tree from BSP
2) go over all touched polygons (to undo any splits due to BSP or beamtree)

3) subspan perspective correction with dynamic width because loop unrolling has no advange with the blitter.
		Sadly, the blitter isn't suited for 8x8 tiles. 

Scanline rendering
I cannto get rid of the feeling that good old scanline rendering would be as fast with some modifications.
Like an ideal blitter implementation would render 4 rows or columns at once, some tiles also speed up the scanline rendering of complex shaders.
So the beauty of the scanline approach is that vertically fast sorting can be used. Some straigt forward tricks with SRAM and registers and Banks and becasue we only have 200 lines (buckets).
X sort could use bubble sort from line to line or at least a sliding window sort, again: register, SRAM, DRAM.
Now what do I gain from deferring the actual blit (of the blitter)? I would use UV mapping. Maybe solid shading does not need to change? Delta for affine texture mapping? Persepective correction?
So every time a polygon ends, this triggers the blitter to go through a linked list.

I read that active edge lists can become quite big. So I assume that I do actually access DRAM. For sorting I would even like to use the blitter copy blocks.
Maybe here the memory comes into play? Split up the edges into two chunks by an edge in the center. If it is not vertical enough, just use its x position.
Then proceed with this chunk, but what about edges entering and leaving?

The only thing we can do is bubble sort locally and export each leaving edge to our neighbour . How would memory deal with the bubbles? So x entries at both ends actually need to travel past.
Can have some thresholds here. After exchange we need to merge the imported x into the legacy x.
Avoid double hop. Any x at the ulteriour is sorted into the correct block.
Usually I hate fixed depth trees, but the Jaguar can only show 1000 polygons, and reg, SRAM, DRAM inspires a 3 level hierachy also for this insertion sort it is.
Import may lead to a split of an already pre processed span.

So the idea is that just as with a beam tree, something like a head, hand or weapon, or a spaceship in front of a planet, is solved locally.

Scanlines don't respect bounding volumes. So I could just start from the leafs of the scene graph and merge sort as I go up the tree. Leaf sorting will be fast.
Merge sort can still load large chunks through a queue from both source lists using the blitter and spit out the merged list.

##Scanline algorithm has a lot in common with the beamtree when you implement cache and spill over for the sorter

Of course, beam tree just prays that all the relevant nodes fit to SRAM. There is not way to limit this, while scanline can degenerate to full DRAM.
The minimal data is very minimal. End of current span. Some pointers. With the beam tree we may need to fight degeneration which keeps to many overlapping polygons active. Can I prove that using edges as cuts limits memory needs?
Do I need code to have the tree and all coursers in DRAM? Sector edges may even need dynamic memory as does the scanline algorithm for visi-planes.

4kB SRAM is a tight limit for the GPU. Even for sorting we need to keep the exact edge increments in y and z. And we need the face increments to later compare the current polygon with other edges, but it would be okay to work on rounded values: 16.4 bit for z and 9.4 Bit for x and 8.4 for y. Bresenham. So basically 32 bit per vertex. But we also need a 10 bit ID to — after sorting — link back to the mesh . UV and shading could sit in another lword. Sounds like phrases . So we need a phrase in SRAM and a word with a link to this phrase. Words can be (bubble) sorted in the registers and carry a link to the phrase which in turn links to DRAM.

Let’s sort 4 rows in one go. So we need 4 words for each edge. 1000 words SRAM. 256 for sorting. 64 edges.

In a second pass merge sort the results from the child nodes.

Global Bubble sort loads everything again per scanline, but the blitter is good at this. We don’t care about sub-pixel sort. For bubble all edged which move left than +-4px are considered. Steep edges are quicksorted and then merged with this. Or let’s quicksort 32 edges and bubble the rest. Need a sorted list of abs(slope) so that a starting edge can kick out others. 

What about more passes. For the edges pack x (y0 y1) int delta x , x carry bits for a few lines. Just sorting on screen. Z is a different matter.

Rough to fine and sort blocks. These kinda explode. Merge sort blocks, but only with two blocks overlapping. This gives us about 50% decision on the actual sorter. So that is does not feel useless. Cut off the tails and sort those all using quick sort. We merge them back in because I don’t actually want to deal with CRUD: don’t mange steep slopes using state.

Branches and branchless workarounds are a bit slow in JRISC, so quicksort would probably be also used inside of a block.

This x sorter eats through the x pattern and stores ID lists in DRAM. And it loads new edges from DRAM. So it needs to keep the complete active edge list in SRAM. Just each edge is just a word. That is it. If I swap this data, I don’t know why I don’t go full tree mode.

Oh hey, what about I first sort all edges by their slope. The most vertical edges get their slot in SRAM and I have their list of . Sounds like a waste. Fitting all edges or a fixed part is waste. I need to have the SRAM buffer as full as possible. I think I could just evict random deep slope edges and insert new edges. I don’t even know if I should sort the new slopes. I need to record which edges did miss the processing in which lines. I log denies and evictions in full vertex format in DRAM. Then process them in a second pass. This is similar to sprite limits on a line. There may be a few lines in a few frames where I hit it. So the second pass is short. Main problem: merge with the regulars (space has been reserved in the list of lists .. ah, merge is not in place. On Jaguar and single pass this hurts me.

So a second pass can then “race the beam” and not sort z (Jaguar cannot translucency and I don’t like transparency) but just find min z at ever pixel center. Ah, still there would be a lot of dz/dx . Overflow exception could happen. Maybe we can reuse the code. 

We would ignore some faces and compress the others into RLE of top face. Then merge. Again the faces will be emitted only for some x. So merging only starts there. (And ends early if no polygon covers the rest of the scanline).

The exceptions mean that texture mapping and perspective and warp around happen in another task. Actually I could guess the timing by now and use an overlapping frame buffer and render just in time to at least reduce latency here in. On the other hand I would like to keep the blitter busy and draw the previous line. Maybe sweep the buffer usage?

Y sort can just reuse the code. The scene graph will produce roughly presorted vertices, especially if I sort children by cg (huh extra cost pre). QuickSort would work similarly well because in the later passes the blocks fit into SRAM. So, bucket sort may speed up this. Buckets flow over in a global buffer, which is later merged. So, buckets instead of the previous line splits. 

Passes
Transform
Clip
Sort y
Sort x
Texture wrap / decals tiles as grid same pass as
Perspective correction: clip UV to visible spans