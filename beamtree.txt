Thinking about "fight for life", each fighter could fill a beam tree and then we could note inside the leafs with which other leafs the overlap (double link, or links[4]).
Can I still obscure a portal? Break it down into one player, then on the other as if it was behind. Gets nasty when Z sort is not clear.



Beam tree favors occlusion culling over view frustum culling. We do this because existing games slow down when the enemy almost fills the screen.
Here the level ( background ) behind the one enemy is more culled by occlusion.
A dongeon has a lot of portals.
Ah still, with the low detail on the Jaguar, view frustum culling is more important.
This leads to a 2d beam tree (near plane is clipped). No need for floats thanks to the simple range. The cost of 32 bit multiplication make any short-cut attractive.
In 2d the shortest cut is only check occl on scanlines and pixels. 
There does not seem to be a cut-over from tree to list. At least it is not here. Actually, elsewhere I consider fat nodes in the tree
to optimize the generation of the BSP when combining multiple convex polygons.
I feel like this just fits into cache memory.
I could even accept the hardware z-buffer for small polygons.
Like everyone covering a small tirangle area renders a solid color ( a byte = ID of the polygon). For each small triangle I read the frame buffer into GPU cache.
Deferred texture mapping. Hmm, JRISC would extract spans, calculate the perspective correction for the texture and send it all to the blitter.
Hmm, quake software renderer only uses spans. Consicering the blitter, this makes sense.
But JRISC could extract spans in all 4 directions for const-z shenigans.
So it goes like 

LOAD
XOR with own ID in every byte
JZ "phrase mode"
cpy mask,r1
and IDs, r1
JNZ or so

This feels weird. I really should render high detail areas using the z-buffer. Even 4 cycles per loaded texel is faster than all that JRISC stuff I plan.

It seems that the brushes of quake really make sense. Convex bodies don't need a tree to resolve internal collisions.
So I should not build a tree. This is true for 2 and 3d. With two convex bodies separated by an axis, one edge of one of the bodies is the only splitter in a small tree.
But the moment they collide after projection, I need to catch up with my tree building? I can try to cut in a way which isolates the overlapping area.
Also I don't want real 3d collision in my demo / WIP (no dipping into water). So no cutes between polygons will lead to new edges for a tree. For z sort I can just use any pixel where polygons overlap,
or I can resolve this in 3d using an ad hoc BSP ( one of the polygons will have camera and other polygon on different sides). If this is indifferent, these polygons will not overlap after projection.  

When drawing a triangle strip, the first time faces flip, visibility needs to be started to be resolved.

For a beam tree I need to check how three edges cross after projection. Two of these edges may already form a vertex in a beam tree, another comes from a polygon , for example.
Back projection into 3d creates 3 planes which pass through the camera. We get each normal from a cross-product.
We want to know if the edges run (counter-) clockwise.
For this we need the "sign" of the enclosed volume.
But the sign of the volume spanned by the 3 normals is the same.

Texture mapping also likes an 3d approach. We ask how the camere hovers over the (infinite) texture and ray cast the texture.
Using sub-pixel precision edges, the edge-texture alignment is no worse than if we go indirectly over the edges, but we can reuse more information across parts or have less rounding due to a more direct calculation.
Also ray casting has no problem with clipping.
But on the other hand, we would need to match the texture infinite plane to the triangle plane in the static geometry .. so the indirection stays the same?
Regarding the screen borders, I could project them into world space,
or I could use some integer factor of screen resolution in camera space,
or I used normalized device cooridinates, skeewed so that I can have two axis aligned planes and two diagonale planes, both of which don't need multiplication and thus no rounding.
Do I want a special case in a portal renderer gone wild ( aka beam tree ) ?
With variable precsion the last multiplication has high cost.

Clipping happens in 3d because one vertex of an edge may be behind the camera. The typical projection matrix in openGl still allows a 3d interpretation if we don't matrix multiply with camera &* world Matrix .
To check if an edge passes inside of a corner, we calculate the volume spanned by this edge, the corner ray, and distance vector between camera and a vertex.
We can thus check one edge against all corners. But we can also check one corner against all edges of a convex polygon. So cache the bits of our mesh? We have this dependency graph for this.

The viewing frustum is special compared to other portals. Two sides only cut each other at the camera. General portals may be skewed.
The code can be sped up a little because there are only 9 "fields" where a vertex could land. But with skew this is more complicated.
Boolean CSG creates the shortest code, but cannot take advantage of the frustum properties. So lets stress portals! I would even accept a near plane. No need to die on this hill.
The cuts give us t, the cut position within the edge. Later we can use this for textures and shaders if we don't want to use the matrix inversion method.
To compare cuts, I use fractions ( aka homogenous cooridnates). The calcuation then should look like a cut between two portal faces. Then an edge either passes below or above this corner ray.
This is cross product and inner procuct. And some 45Â° rotation done using ADDs. Distribute everything and check if it is the same.
The niche thing with the cut is that I could store temporary values and reuse them for the texture, transformation or another comparison.
In vector languar the cut is: inner product of portal face normal with edge start position and with edge vector. Gives us nominator and denominator.
The corner is the cross product of two portal face normals. I don't see a similarity.

Cutting works on vertices, edges, and polygons. If I want to do this after transformation, yeah, I need to transform all vertices or check the graph. Matrix mul is slow on JRISC.
With cutting as first step I only transform visible vertices ( or their cuts ).
With all occlusion done by the beam tree and portals, I don't need to respect any order. Just follow the visibility-marks in the BSP-tree or portal graph.
Now applying cuts (in 3d for the vertex, delta (UV) along edge times t for texture) and transformation can run in parallel to the blitter.
Now certainly the blitter is not the bottleneck anymore. I feel like I cannot fit this into scratchpad RAM. I don't want to pull in Jerry in my prototype.
The complicated edge calcuation does not allow to call short and long spans in a trapez.
Anyway, long spans would undergo subdivision so we keep being limited by the GPU.
The nice thing about transformation is the simple nature of the matrix multiplication for rotation.
I could just let this run through a small queue for the next triangles. If the buffer is full, use the blitter to write out. No problem.
Though meshes could start from strips and triangles and then use 5bit relative indices like jumps. So I should probably not transform more than 32 vertices. This is alreaday taxing on the memory size.
Can I use LoadP with some clever structure? Maybe simply fill out this struct with x,y and u,v and intensity and call it a day. In other words: I could not load the full 16.16 fixed point values for the blitter.
This would already be two phrases! Some packing: 9.16 , 9.16 , 6.16 , 6.16, 8.8 . Still two phrases.
Looks like ( I got this from N64) it is really worth to transform for the next triangle and have markers in the mesh-stream which double phrase to delete from the cache and which to write back.
Notice how StoreP is buggy as you never know when store has finished. So double phrase write is impossible. Also the high register is shared with reads.
Even Read after Write is critical because the write value has its own register in the bridge to the system bus.
From the manual:(one internal load/store or two external loads/stores can be pending without holding up instruction flow).
Markers in the mesh should of course keep values which are used again after a short time.
Values which will be used later need to be written out as early as possible.
Now apparently we need to make sure that 2 more values are written out before this value is read back.
Regarding the high register, we could set the GPU to bus hog and Store, StoreP, check blitter, start blitter, check blitter.
What about DRAM refresh? I cannot guarantee anything. Seems like I need to stick to Store or use the blitter for batches.
So for each mesh transform all vertices which are accessed from triangles far apart in a batch. Copy to DRAM using the blitter.
Then while going over the faces, use a cache in SRAM and occasionally LoadP, Load, use (probably unpack), LoadP.
This is for the enemies in "Descent" or "Sky Hammer". The level would be a tree with markers. I can only cache like 8 vertices as I walk through the tree. I guess 50% cache misses.

JRISC is not good and jumping. And linking even costs more cycles and registers. Maybe I need cross product and inner product only once per overlay? Then the blitter loads new code, but keeps the vector routines.
The vector routines return to an address stored in a register. Or just use macros and more overlays..

I know that "Descent" checks for flatness of poylgons .. but Doom does not. I don't want to. I think with enough precision here again one glitch per hour is realistic. I don't think that the rasterizer crashes.
For edge interpolation I need to invert a 2x2 matrix. Every polygon is split into cuts with the frustum and other edges which only change one of the screen cooridinates.
The other edges between are paird. The side with spiky angles starts. The other side needs to chose either adjacent edge as partner.
On the other hand sub-pixel correction per line is not that expensive. fraction * all the deltas. Fraction sure is 16 bit. And as a correction this does not need more precision anyway.
Span interpolation already needs to divide by span length every scanline. No new division! Same quality as 2d deltas.

For perspective correction we calculate first and last vector and again need interpolation with its division. With span interpolation we may be tempted to do the perspective correction on the edge.
Accuracy is no problem because for longer spans I switch to subspans anyway. Ah, then I need code to calculate on the pixels. Seems like on the pixel is the way to fit code into memory.
Interestingly, with subspans on pixels, I would have two sides which need division anyway. I could get rid of this weird 1/2, 1/3, 1/4.
On good hardware I would align to phrases. Thanks to the bugs I could just try some adapative stuff. Near side a bit longer and far side shorter.
The repeated bulk span is given by the speed of the DIV instruction vs the speed of the blitter (and all the JRISC code).
I feel like JRISC is so slow that this results in 32px spans. So adaption is key here also. Revival of the 4 directions rasterizer! 

Normalized device cooridinates give us integer z values for a z-buffer, but beam tree does not use a buffer. Instead in each leaf we need to sort by z or even find a cutting edge for example for a ship floating in water.
Back-projected cuts between two edges of the beam tree result in a vertex and a ray to trace through the two polygons which we want to sort by z.
If all 3 rays agree on the sign, we are done. We get the vertices as cross product. The z depth of the ray can go over texture base system, with a cosine factor for comparison,
or we just formulate it as algebra based on polygon vertices: Invert a matrix using cross products. We get a value out of this, or two.
Of course there is some 3 volume sign interpretation to this. We have the beam and look at a segment from one polygon to the other. We have the cut between both planes. This tetraeder has a volume.
We sure need a base vertex of each polygon and the surface normals. The cross product of the normals give use the cut edge direction. We don't know the length.
Ah, this does not work out. Just do it algebraic, and the addition of fractions, and then look at the sign.

I think that I will allow cuts only for transparent objects like water. When cuts go through a leaf, I let the pixel shader decide about 7. Not much transparency allowed in my low performance scene anyway. Jaguar needs JRISC for transparency.
Otherwise I could probably find the cut of a cut on an edge of the beam tree by a long and tedious calculation.

I want to stop to think about tree optimization. To show the principle, I use simple geometry. I once thought that 3d looks good above 1k triangles.
Even here a totally degenerated tree does not take much time. I can keep everything in DRAM memory to pull in more precision later.
For real first generation 3d games, the count is even lower: Virtua fighter without 3d hair, stunt car racer 3d, elite.
I want to do descent. So a level where we see 100 polygons and one enemy with 20 polygons.
Or need for speed: One other car with 20 polygons and a street section with 5x20 polygons.

Triangle strips work well with beam trees because we will insert the shared edge into the beamtree.
Then at least we don't cut the next triangle.
I should sort strips front to back ( closest point of each strip ).
Backface culling cuts the strips => more to sort.
Even with a BSP tree I could go front to back and in each leaf sector I can try
to continue with the edge of the last sector and then go around.
For Z-Sort a hierachy of spheres would be great.
I still could try to go over edges ( the longest? ).
In a connected mesh .. ah so maybe I will forget some faces.
When I pop out of the hierachy I may need to clean up some leaf nodes 3 levels down.
Likewise the mesh walk is allowed to see into spheres escalating 3 levels up.
I think that objects will not be that big. Levels?

For optimization I take the longest edge. I may allow backtrack if I cut two many triangles?
In a prototype I should stick to greedy.

Why do I use spheres? Because noncompact polygons don't work well for sorting.
But pruning works the same: If edges of the BSP tree don't cut the sphere: Ignore!
If the cut, but no vertex is inside: ignore.


Clipping to viewport and portals and to merge BSP needs a division.
On the Jag with fast MUL we might want to use fraction also for compare.
Sometimes we get to close to zero. One code path would be to pull in more precision on demand:
But we had to round the factors to 16 bit. Now we need to MAC  ( AL * BH ) + ( AH * BL ) for the next 16 bit.
Highest precision max once a frame?
I think I calculated that I need three factors.
If I want planar bsp without triangulation, I also have the rotation multiplication.
I don't know how to do floats here. I want to translate and the float.
Hopefully the same exponents enter all products in the MAC.

We have to transit to pixel some time.
Due to the planned const-z shader I hesitate to use scanlines nor kd-trees.
Anyway, a polygon becomes smaller and may only cover on of our const-z directions:
horizontal, vertical, both diagonales.
Then we need to get the extreme pixels which are still covered.

A small polygon may even fall throught the cracks between the pixel centers.

When the cut between three edges as area to close to 0 with 16bit = 65000 subpixels on SD screen
of 320 px we have a high chance to be away from a pixel center after DIV.
The Jag has a config register to set options of div to get useful, large, numbers, even
32 bit maybe ( fixed point ) .. so sounds attractive.

So we don't know the order of cuts on the vertex on comparison.
We have a tree, but some edges appear as ghost in other nodes. Just add an attribute for this
linked list of ghosts in the corners.
We just use the rounded value to determine the color for the pixel.

We need to keep the straights straight.
When we merge two BSP, we need to be able to trust the comparison with parent splits.
Those splits are not allowed to be curved or tesselated in an uncontrolled way.
We know the ghosts and copy them into the result. What do we do with them?


Lets say I have a convex polygon in our BSPt and want to split it further.
Around we have a ring of : edge, vertex, edge, vertex
Additionally there can be ghosts in the vertices.
Theoretically I could have nearly parallel lines and thus ghost on an edge.
Now the split may stay clear of the vertices and the ghost ends up in only one of the children.
Otherwise the ghost can be in both. So many references to one ghost-creator.
I don't think that the ghost creator is interested in its ghosts.

#Comparison with Doom coverage buffer
Using the edge equations avoid strange jitter like the coverage buffer in Doom.
Even the comments in the visiPlane code mention that it only works well due to the fact that edges filled the coverage buffer .. and not sprites with transparency for example.

#flat polygons for architecture and machines

BSP in the scenery are described by a triangle with computed solid geometry after camera rotation.
One would think that this gives us complicted vertices,
but the BeamTree is concerned more with edges.
Edges between planes .. even more multiplications.


#B-Tree

Our Memory container is of course our beloved b-Tree. So I store the binary tree in an n-tree with
a tuned size. Over that size, b-tree nodes split. Below they merge.
A node will first compact itself following the binary tree structure in it.
We don't have sectors in RAM and pages are not well known. So nodes are not usually aligned.
They can grow to both sides until they collide with other nodes.
Then the larger node will split.
With large free regions ( I keep a sorted list ), I may want to pull in nodes from the outside,
so that they better match their position in the tree.

#Demo SceneGraph
I could use spheres, but I have trouble to use them for LoD. Somehow they introduce squared surfaces and cones.
So I could create a random tree with convex leafs ( asteroid field) and just aggregate by proxity.
The bounding volume is composed of all the faces which don't see the siblings and then
the closest two vertices of from different siblings are connected, then the next, until the volume in between is triangulized.
Inflate until nothing sticks out and the shape is convex. Simplify small faces and angles.

Splitting
Sort by longest, prefer who does not split others. I would guess that there is a natural order comming from our trees.
So we look down the tree and do a red-black tree kind of rotation to promote better splits. It is a bit like a chess game: pertube all the splits.
Thus it may make sense to run these on Jerry: Like in a chess game it tries multiple splits and then procedes with the tree.
If according to some heuristics, too many splits happen, Jerry rotates the top tree and again tries to build a BSP. 
Meanwhile, Tom goes into the depth of the tree.
The tree naturally has leaf nodes, but we may want to rasterize before we get there if the area of a node is small enough .. max width small and number of edges per scanline small.
Then we go by scanline and use the tree to pull the active nodes and sort the edges by x.
Like the floor in Doom this allows us to run the texture over all splits.
It even makes sense to instead use 8px regular splits on those spans for perspective corretion.
Feels like we should be greedy to find the complete uninterrupted span of the polygon and walk the tree for this, if necessary.
So we go down the nodes in the BSP tree and when the number of edges per scanline fits into the registers, we switch to scanline.
And we could try to add nodes (siblings or their children) into those scanline where we don't reach the limit.
Yeah maybe an extra code path for short subspans is useful: Every pixel is perspective correct and we use the blitter only to StoreP.
To have a simple shader state, texture caching makes sense. All visible mipmap levels are decompressed (multi-texture) and lit on demand.

transition to pixels

ensure a blitter span stays clear
	of
		real edges on screen
		seams in the texture atlas

For concave node on screen I could rasterize all edges using a spanline renderer.
For a concave leaf I need to sort vertics by y anyway.
maybe I can check if edges cross between vertex.y ? Hmm.
I don't want unecessary splits of the blitter run ( perspective wants them, but hey ), thus split by scanline and then the edges are only used to check
if the current span is still on top. Kinda like the merge of Doom floors.

The other way may be that the beam tree is too lazy to check for high precision in case no pixel is nearby. This may cut down on the real expensive MUL, the tail.

The typical problem will be that we have a beam tree with vertice which are no real vertices, but crossings.
Now we could check between which scanlines these cross.
If the crossing is far away from the lines, I can detect that ("worst case"(+some if you don't trust your code)).
It is still statistical. Makes not sense to do infi precision here?
Breadth first search? Try to isolate cases 3 edges and 2 edge+scanline whoever comes clear first?
I miss the synergy with rasterization. I mean, I need to isolate scanlines relative to real vertices, yeah but also for crossings.
Otherwise I need to raytrace. Rays to crossing ?? Rays can only shot left or right around an edge.
Rays can be rounded. Hence for small polygons raytracing on CPU may win.
Blitter spans don't follow naturally.
About synergy: if I start rasterizing corners of a polygon ( node ),
These scanline become the beam tree splits. Further down trees are spli into upper and lower part.
Make sure that there are not so may nodes below this ( small subtrees ) to avoid exessive splits.
Also frame to frame coherence only works with a beam tree.

When there is a group of faces all facing the camera then there is no occlusion.
I want a unified approach for LoD and perspective correction and lightning which recognizes the importance of the normal of a face.
Almost faces, aka organic, smooth surface should profit from this also.
Linear inter polation in the blitter still has to recognize the boundaries.
So I have a given beam tree from another node in the BSP which may contain occludions for this node.
But I don't use this node to split internally.

Maybe I can use this group apporach for all meshes. When I know that max 16 polygons overlap on a single scan line,
I can use scanline rendering to solve occlusion.
Rounding is allowed as long as I don't touch real boundaries of the BSP.
Of course, with gaps, I have a problem. So I need a "watertight" flag, which still depends on a normal or portals. I guess I can have portals in a BSP-tree.
Overall, this feels like it needs more code and not like common sense to allow rounding.
May still be interesting for dead end caves behind a simple portal (interface of a parent BSP node), just to show that there is no road-block.

I cannot unify trees with portals. I want a dongeon, so like with descent the level will have a portal base. A graph.
The bounding volume hierachy lives on top of this.
Unlike a pure portal renderer like descent, the portals only live in really portal like places. Just like all other games do it, I guess. Like Quake on PSX.
Thin structures like columns or spikes don't lend themselves to efficient portals.
Texture with transparent pixels is not what I want due to the fill rate problem on the Jaguar ( Jaguar does not count background pixels for me).
It is a slippery slope. Let's allow overdraw here and there ...
The better way a correct demo running with zero-overdraw and than I profile it and may relax this constraint to speed up the slowest frames. 

Another way would be to do raytracing on a low number of polygons. The ray position can be rounded to world space.
This may be needed for some cases: Enemies far away . Plants. When I don't want to do LoD.


##rasterization and fusion of spans for the blitter

I need to find the relevant scanlines.
for each scan line I try to set a blitter line on the screen ( longest possible span and I may even be allowed to round the ray directions in world space),
but also in the projected space on the texture atlas with the given rounding in the blitter registers.
Anyway, I need 2 paases:
1) create beam tree from BSP
2) go over all touched polygons (to undo any splits due to BSP or beamtree)

3) subspan perspective correction with dynamic width because loop unrolling has no advange with the blitter.
		Sadly, the blitter isn't suited for 8x8 tiles. 
