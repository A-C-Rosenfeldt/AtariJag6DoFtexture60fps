After clipping, affine texture mapping does not work anymore. I guess that the KISS method is to clip perfectly, but then interpolate on the edges.
I do not like that I need one extra division per scanline to recalculate the delta. Divisions should be used for perspective correction..
uh but which also needs one delta calcuation per scanline. Triangulation would indeed avoid this. But then again, I have one division free per scanline iteration.
Guard band for very small affine triangles. A nodge towards perspecitve correction for larger. Maybe have an executable with either code path / or a quality option?

Sorting (by y) is so incredible fast that I want to start with scanline rendering for the visibility determination, but defer the rasterizer due to code cache size.
Active edge list can be a b-tree with root in internal memory and leafs in external memory.

Portal rendering. The beam tree leaves are convex polygons .. so portals.
I want to improve on Sky Hammer in the scenes where there is an enemy covering a lot of the screen or when I peek around a corner.
In both cases, portals help. Mostly I don't get the artwork in Skyhammer. All grey and almost no direction. I will need to generate some CRY textures with caching for shading.
When I find the overlap of two convex polygons, using a BSP tree is not the fastest way, although it may result in the smallest code size.
So we check the vertices of one polygon relative to the edges of the others. The order of the edges defines a BSP .. uh, but we don't split edges?
So what is the result: For each other vertex I see if they are inside of these edges. So it is a bit pattern. Does this help me? Some assembly trick? Did not work well last time.
What if I have both views?
Find cuts:  Number of cuts.
0 one inside one other ( all vertices inside all edges . Check from both sides.). Non-overlapping: Early out. Overlapping feels like collsion simulation and it is true. But I only deal with polygons with up to 4 vertices. 16 compares hurt, but I don't want to pull in separating axis theorem or CJK iterations and am not interested in contact points here. Maybe recheck later.
1 one.vertices, cut, other.vertices, cut

Crossing two vertices on the other side.
Does this work for the whole cone ? Check that camera is above polygon surface. Vertices of the polygon surface may be behind the camera. The latter test is the naive way to solve this. But it would need to chain divisions or at least rationals.
homogenous coordinates?
Other.Edge through face (vertices on both sides). Other.Edge . Volume = camera-Other.vertex  x   Other.edge x this edge  .. sign changes.
Early out vs collect signs first (branch free, optimized JRISC can be fast) and divide later. Okay, is probably not fast due to floats, but uh..
So on each polygon we get signs per vertex, and changes per edges. And we get links between edges. We get links because we check each edge with each other edge.
To justify this, in the outer loop we go over the polygon and calculate camera x edge. Then in the inner loop we inner product this with the corner rays from the camera.

The result is again a convex polygon. Calculate z. Sort. Ranges. Slope if deltaZ>2. X Ranges. Affine Slope for delta(round(X))>1.
The remaining space in the portal is not convex. But we now only need to cosider the visible edges and vertices.
The newly drawn polygon gets its central (longest) edge extended. Repeat recusively.
When drawing a triangle stripe/fan, the shared edge is extended. I don't want to pursue any heuristics into the third polygon.

How is the counting if we have a fully-in or fully-out early out? Like two convex polygons are fully inside the screen? I could try to profit from the code: Find the ovrerlap. Check z.
So we would allow up to two convex polygons in a leaf. When then another arrives, the old ones need to be converted into a BSP. Lazy BSP. If one polygon is fully inside leaf, but next is not: BSP!
Do I want 3 polygon inside checks? Maybe the new polygon is occluded? But I only get a probalistic answer. The new polygon may be fully inside the already drawn polygon, but behind.
So I want 3 inside relations? Or rather 6?

To allow a fast implementation of Elite, I should probably use the shiloutte of the ships as rough splitters, and then draw the polygon faces.
The nice thing compared to an indoor level is, that I can just sort by z on screen. Or maybe mix in apararent screen size ( space station, planet). Simple rule, easy to tune.

As a tree this would be kinda like a B-tree? So not binary. Each node divides the convex parent into one or two convex children, plus the rest.
Tree merge needs 4x4 comparisons. I really want this to happen while the blitter is occupied, but I don't see how.
How do I rasterize a half moon? It can have two spans per scanline. So I need to find the splitting vertex.
The floor line merging in Doom is a bit suspicous. I would understand mergin in DukeNukem3d with all the portals, but the Doom BSP has less splits, I think?
Anyway, in a true 6DoF I feel like "half moon" covered polygons happen a lot and the coordinate independent split feels weird. 90% of the speed of a full merged solution.
A complex polygon renderer can run parallel with the blitter. So we want complex leafs. Then we can calculate the next leaf (sort y), while we rasterize the current one.

Setting up the blitter is quite expensive.
So we want to draw as long lines as possible.
People don't complain about squares scrolling through.
Thus switching the directions ( x,y, both diagonales ) is okay.
Optimize to minimize scanlines and for minimal zchange ( hard limit on max z change)
Small triangles are drawn using affine transormation.
Quake and descent had scanline spans.
So when the scanline is really long, divide the rest in 16px or 8px spans.
In between, switch on perspective correction on the edges.
The top and bottom tip can stay affine.

Set up changes the least from line to line for affine mapping with subpixel correction ( we don't recalculate delta per scanline).

Color Ram can be used as texture cache because I don't plan to use palette in my artstyle anyway, but I need all GPU RAM for vertices. Or whatever, anyway,
Skyhammer showed that the small cache is best used when we draw quads.
The blitter can efficiently copy a rectangle from DRAM to color RAM. I mean, yeah: 2 cycle read, 1 cycle turn around,  4 cycles for write. But for a Jag this is fast, especially when we zoom in, or reuse tiles.
Again, the 8x8 quads on the output are beat. Just like on N64 the way to go is to split up a large polygon into a grid of quads. But similar to 3do we rely on this also for perspective correction.
I guess that recalculation of the gradient per scanline is faster than drawing two triangles. Maybe we can draw the top and bottom of the quad as triangles.

Also: Drawing direction can be choosen, for longer runs! And we can use rectangles for longer runs. Regarding the beam tree: Maybe we don't fuse leaf nodes if this busts the cache.
Quads don't dominate our geometry. We can still have Doom Mesas. We load rectangles based on the rays casted from the BeamTree leafs.
For small quads skinned onto a model it makes sense to to store them in a page. Though one page flip per 16px .. just read how many cycles each pixel needs right now. Ah, the blitter eats one cycle per line change and the page flip would eat two more.
This hardly justifies another code path. We don't cache on scale down!
Or at least we would only cache the output. But it does not help much as we have page misses all the time anyway.
The Jag has enough RAM so that we don't need tiles.

Squares are so attractive because they don't need the edge calculation.
The spans can be shorter and the GPU is still faster than the blitter.
Squares only make sense for large triangles.
Spans are as fast because divsion .. even though it inssist on 32 bit, only takes 18 cycles.
The blitter cannot do 4 px in 18 cycles.
Only if I try to do other stuff ( interupts ) while drawing the span, squares / rectangles would make sense.
As we all know there is no 64 bit texture source beside DRAM.
If we go for 50 fps, we could render to linebuffer .. do we go ?

For perspective on the edges ( const-z renderer like Doom ),
do I calculate exactly on the edge? Maybe for this precision thing?
Like I use 1/z and multiply(2 MAC) with the edge vector in texture space.
One division ( fixed point ) for linerp. So per line: 3 div, 4 mul.
2 Mul with fraction to go on the first pixel center.
Pro: Can be proven to stay in triangle. With low z variance we do affine anyway:
We can do multiple lines with one division for width and 2 Mul for subpixel.
Still seems faster than to calculate the diagonal.

Calculate on the first and last pixel: two div, 4 mul. integer div.
Bresenham to jump on pixel center. Adds for all 3 components of homogenous coordinates.
Pro: perspecitve closer to actual pixel. natural transition to affine.
Staying inside texture triangle can be forced by precsion on demand.

So I always calculate first and last pixel on the GPU,
but the blitter already for short spans allows me to write unaliged without RMW.
Maybe it makes sense to write up to 4 pixel into the source register ..
Todo: Test if 2n sourc register is shifted over without a read?
Still with 4 pixel like in Gouraud shading,
it might be interesting to fetch the texture using the GPU.
GPU master is 64 bit. DRAM is 64 bit.
eat dupAlicated phrase access, 
load
write into blitter
phrase mode
Still: A second code path? Lots of GPU cycles on short spans???
At least need to combine a short and a long span for this.
Oh, registers get crowded.
Or should I use the blitter to load the texture into GPU RAM?
Then use GPU to fill the phrase at the end of the line and blitter pixel mode for the 8 px spans.
No. Avoid all the storage.
Copy target has 2^n width.
GPU:
	2 add, 2 adc, move, shift, or, load, add light (saturate?unpack or high word + carry)   8 (4)
	(fraction."sign" xor destination.bit0) and shif 16 => shift_px and or  5
	saturated light is what makes the blitter the winner.
Gouraud is similar: needs <=4 GPU pixel. If saturation? Be sure to start on non-saturated side or from the middle.
	

To avoid divisions for short spans I thought about a lookup table.
Span length, subspan or 1/x lookup and MUL. MUL is faster of course. Oh my. Also less code.
Edges are expensive. So hide some of the calculation in a span?

If packing on GPU would not be so slow,
Then even the UV need the 16 bit shift.

n-gons help with long spans. Like Descent: If same skin and some tolerances (z, same face) are met.
I could even do scanline render for concave.
