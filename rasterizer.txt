Perspective correction is slower than affine texturemapping because I need to also fill the increment register.
I may need to check the SDK code, but please, don't change horizontal increment for affine triangles.
Small area triangles need to be affine. Slithers are extremely slow with correction. Also check z-dynamic to apply this render path on as much triangles as possible.
Reuse of the increment is also a reason why pure scanline rendering is a bad idea for texture mapping, less for Gouraud, but certainly for SRCshaded textures as in skyhammer.
JRISC lacks certain instructions to efficiently fill the texture registers. Nothing is faster than naive:

;increment along edge and fight the slow branches in JRISC
add r10,11 ; eigentlich: check sign of r10 ? That would mean the loop depends o
branch on carry ;to select delta. Bresenham creates two different deltas
add r1,r8	; s
add r2,r9	; t 
add r13,r14 ; x  nur integer

When I keep increments in the blitter register, uh, I save two registers on the GPU. So how many do I need?
(s,t,(xy,counter) =4) * (alternative jumps=2 + akkumulator=1  =3 ) = 12  

;interleave words -- okay ist jetzt nicht so viel komplizierter als der doppelt Bresenham
interleave instructions{
cp r1,r2
cp r2,r3 ; could swap these two. Would not make much of a difference, but
and 10,r3 ; Maybe I can deliver r3 to or ? But there is alredy shift quick for this.
|
cp r4,r5
cp r5,r6
and 01,r6
}

interleave {
shift r5
or r3,r5
-- uh, wait for blitter?  load 02238; btest 0
store -- interleave is mandatory to reduce blitter idle time. Maybe MoveTa instead of store, then flip page (all others are off the score board because reg-reg calcs only), then store, then flip back.
|
shift r2
or r2,r6
store displacement
}


Bresenham needs two decisions which I want to implement as up jumps to eliminate the loop jumps. Taking a jump costs 3 cycles.
Both edge increments are round half up. So I know the favourable code path

loop{
other right
favour left
block optional break if counter
favour right
other left
}counter was already elsewhere

So all combos only need one jump, , but other right, other left . Code duplication lets us reduce these 3 jumps to 2.

store F0220C ; screen position. A2 Okay, here I am glad that it is only a single register. X is low word. For 3 direction const-z, the code is not allowed to care.
store F0223C ; counter . For max speed I could detect changes

We have enough registers. Any ROR, NOT will save a register, but cost a cycle. Same with double shift.
Now when does perspecitve come into play?
13*2=26 cycles just for storing values is as long as a division. The edge calcuations take as long. MUL is not async to it has to be added.
So basically we can say that the two DIVs on both edges are not the bottleneck .. if I can spread them equally.
There would be multiple scanlines in flight.
# UVW and edges -> DIV, second data interleaving , wait for blitter
# process DIV result, kick off other DIV, first interleave -> TA, linerp via lookup, mul 

Quake has special cases for linerp. I want fast corners

load base+delta_x, target
compq deltax, 3
if smaller then jump target    ; if there were not so many funny rules around jump, I could put two jumps butt to butt ... Bresenham already does the up jumps. I want to reuse code verbatim for perspective
	x_end=x_start : do nothing
	delta_x=1 : set xy integer
	delta_x=2 : set integer for akku and increment  .. so not in all cases. Use addressing mode with offset

default (no jump?) : It is a shift. How do I detect those without jumping? 
bitscan
add silly_bias,s
shift s,delta_x
if zero flag
{
	shiftR s,increment
}
else
{
	setup{cp buffer_address_in_localSRAM}
	add delta_x
	and wrap_around   ; rem ODer page aligned und einfach mit bset das carry killen. Also die addresse muss mit 0 enden. Sonst muss man auf sub umstellen. Also delta_X signed? Aber bitclear statt bitset ist ein anderer opcoce!
	58 LOAD (R14+Rn),RM 
	for x,y{
		cp increment32
		mul divisor,increment32   .. uh 
		shR increment,16 ; Maybe here is some synergy with interleave

		ror increment32_cp
		mul divisor, increment32_cp		
		add increment32_s
	}
}
store integer.fraction 

Selection of const_z seeems like a realy good idea. Even though the subspans use fast shift_R, I think we need even more registers and additional code. And I want extra long blitter runs.
Of course, 3 direction drawing is incompatible with scanline-rendering.
Scanline rendering access the bus. Hmm, could try to do it when I will be waiting on the blitter in a minute anyways.

So with about 64 cycles per line, the blitter can blit 8px in pixel mode without fast-page mode. Ah wait read to write cost another cycles. So 9*8=72 cycles per scanline.
So let's say that blitter and GPU are matched on average because a lot of triangles in Fight4Life or BattleSphere are about 16px wide.
It might be tempting to have a queue over the height of a trapezoid. In contrast to interleave of long and short spans, here I can pay back on triangle set-up. And code is clear because the queue is separate and dumb. Draw middle vertex to coners

wait:
if blitter idle then shortcut ; 'Blitter does no care about order of lines
else ;shelve
cmp write_pointer, wrap_around  (or test?)
	== goto wait
	<> store [write_ppointer++& wrap]

: ;second place in GPU loop and later on triangle set-up to pay back the shelved blitter runs.
cmp read_pointer, write_pointer
if <> and blitter_is_idle then load[read++& wrap],store in blitter

ADQ
AND
Load					xy
;these const two more cycles per instruction. This is a clear disadvantage of the queue and shows the need for the short-cut
;going throuhg the queue word by word adds 3 instructions into our tight memory and only removes 3 cycles?
load displacement		st
load displacement		fraction
load displacement		counter
store
store displacemnt only costs one cycle per instruction. Oh, register loads happen on different cycles anyway. 
Shortcut uses the same blitter registers, so maybe have their addresses in different registers? I don't think that I have much left


Scanline-Renderer: Cons: I cannot do const-z texture mapping and 8x8 tiles is hard.
For interpolating values, this is not really so bad because Jaguar has faster MUL than branch.
So I could hit two edge pixels out of the blue, load a whole matrix to multiply (x,y)&Matrix+Offset -> s,t,lumen. Or uvw . And edge propagation data.
The nice thing is that shared edges are calculated only once and the branch in Bresenham does not bother me as much (or the cumbersome branchless coding which all relies and ADC).
Even for individual polygons it seems to be faster to use x_start and x_end in MUL to get UVW. Like, add fixed point. Always keep the UVW start values (uh that costs).
Hmm, weird. This seems to be worse than ADD->Add 0 carry -> mul  or even Add -> adc -1 -> AND, ADD for 32 bit.
MUL has no problem with occlusins, while ADD would need new intialisation on every edge cutting in. To use the 32 bits, the initialisation needs slow 32 bit MUL.
This makes z-sort interesting again. Draw full polygons and only cut out others which don't match the order.
My problem is that z-sort eats into the processing time for only a small benefit here. I hate the tuning hacks like buckets or Qsort.
Without buckets, sorting will be almost perfect. I would use occlusion information only to determine the visible scanlines, but still propagate along the edges?
Maybe I find occluding edges which still keep the edge count at 3 or below? Like The frustum with its free edges.
Portal rendering accepts 6 edges. I guess that edges created by small debris flying in front of a house can give quite the spikes in render time.
I cannot render scanlines and then draw all intakt polygons because then the eventless scanline would be wasted.
Or at least, I could defer rendering, and then on the first occlusion, I render the polygon up to the scanline and switch to scanline rendering there in order not to need to save massive amounts of temporary data.
Just because on typical games, 80% of the polygons seem to be intakt. Of course I would love a symmetric approach.

Only beam trees scale in a sane way. I would use a stack and manage the overflow in natural way. No oppionated hack to repeat code in registers, SRAM, DRAM.
With scanline rendering on the other hand I know how many edges I have. I reserve an active edge list of the same size in DRAM. This list is short compared to DRAM size.
LoadP is a fast way to crawl through the edges. I only need to write back indices occasionally. So, all this drawing data is kept at the edges. Only the indices are sorted so that I don't need StoreP.
Problem is: Active Edge list is as uncool as z-buffer. The hardware should have done that efficiently. Why do I need to write software for it?

At least with pure scanline algorithm I probably have something to draw every scanline and it does not hurt that skipping lines is kinda difficult.
Actually, the concurrency with the blitter is far better here. Base address and shading are only two values which switch between faces.
All the other values switch even within a polygon: s,t,x,y,luminosity.
With blitter control and visible surface determination both in code cache, we can releax and not try to cache any data or do blitter double pass.

Of course, Doom had a boudning volume hierarchy. Beam trees are compatible, but scanlines are also. Feed the bounding surface into the algorithm.
When it tries to draw the first pixel, bait and switch, replace the bounding volume with the detailed interiour. Same for portals.

So it seems like there is no hybrid between scanline rendering and painters. At least I get scary worst case (memory scenario).
Now I am almost sure that I don't have enough code memory to squeeze in scanline rendering (16 bit math, 32 bit math) and texture mapping (texture coordinates at corner, sub-spans, register address)
at the same time. Maybe I even want shading because Fight4Life looks so flat.
I can define a happy path. Polygons with max vertices. Like obviously we need at least 3. 4 happens due do clipping (on frustum) or occlusion. 5 can also happen.
Convex. The rasterize needs to deal with non-convex polygons. Ah wait, that is ugly along the edges. I can only store two edges in the registers.
So, mostly convex. And where was I : Indices to at least 5 vertices .. make that 8.

So it can happen that we cannot write out the complete polygon. To make the sub-span renderer happy, there needs to be a winner on merge and a default on split.
So the effect is like this: Many small polygons in front of one large ( biped in front of a wall ), fills up my memory with lots of "virtual" polygons to draw "around" the characters.
Lets just say I accept as many (additional) virtual polygons as real ones (256+256) and hence have limit for the memory usage.

Z-sort may be a way to avoid this, but is not without hassle. So obviously I have determined which polygons are in front.
Ah, all the large "background" polygons need to be resolved within. Likewise the small polygons should be resovled within their group because most results are easy to process.
The BeamTree is looming in the background because the active edges list needs fast inserts, which needs a tree.
A hybrid solution would be two fold. I check all edges for the next crossing and may skip some lines completely. This is kinda a test from the BeamTree.
Then when the number of edges gets two big for local memory and brute force memcpy, a visble edge is chosen to split left / right.

Polygons may be split onto both sides. So I later may want to fuse them. By using a real edge instead of vertical (from a vertex) or blocks,
I at least safe one polygon from a split. Now this edge may even belong to two poylgons, or it is an edge of an object and occludes stuff behing it : So many cases without polygon splits!
It is still a bit ugly that I want to keep code around to check.

I thought about the span buffer Quake is said to have. It fits the blitter. With a low resolution I might write span starts at pixel positions.
The blitter can clean this buffer. Even if this solves allocation, I still need pointers to jump over other polygons and to advance into the next scanline, heck, even for overdraw.
This becomes a deferred renderer: Draw everything flat shaded with z-buffer. Use blitter (pixel mode) to find span length.
GPU calculates texture coordinates for start and end. Use blitter (pixel mode) to fill span. Interleave this to keep blitter and GPU occupied.
Like for one blitter action the GPU does the left pixel and for the other the gpu does the right pixel.
The backbuffer is for the first part. If I don't mind screen tearing, the second pass renders to the 16bpp front buffer. I hope that Grouraud shading code paths also fits into local memory.
"It normally compares the source data register with the pattern data register," => "The action of the Blitter can be stopped altogether"

After clipping, affine texture mapping does not work anymore. I guess that the KISS method is to clip perfectly, but then interpolate on the edges.
I do not like that I need one extra division per scanline to recalculate the delta. Divisions should be used for perspective correction..
uh but which also needs one delta calcuation per scanline. Triangulation would indeed avoid this. But then again, I have one division free per scanline iteration.
Guard band for very small affine triangles. A nodge towards perspecitve correction for larger. Maybe have an executable with either code path / or a quality option?

Sorting (by y) is so incredible fast that I want to start with scanline rendering for the visibility determination, but defer the rasterizer due to code cache size.
Memory managemnt is like: count number of vertices for each y "bucket". Then fill in the vertex IDs. Bucket sort.
Even packing in internal memory would be possible. load ror add rol (either counter or increment) store.
Quicksort and Mergesort are also good conentenders, but have weird worst cases when I take internal memory constraints into account.
Finally, for cockpit view with like 120 lines on screen, bucket sort just plain wins.

Active edge list can be a b-tree with root in internal memory and leafs in external memory.

Z-resolution pulls in float too often. So we reduce its count. First only for xy overlap (perfect). Then check for z exp, then z mantissa, then cut line projected on screen (32 bit probably).

I determine visible surfaces in a separate pass for profiling. But is a bit difficult to destill the clipping information. I seems like I need to repeat the active edge list stuff in the next pass.

Small triangles use the affine rasterizer. I use the guard band to allow (small) triangles to use this fast pass independently from some rather arbitrary clip. Or do I? Whan about occlusion?
Maybe I should not play tricks. Affine is only for unclipped, unobscured, small area*delta_z triangles.
Anything larger uses edge interpolatation and then span interpolation. So actually, I want to correct perspective on the edge if I have to interpolate the span anyway.
For larger triangles add subspans. I know I loved tiles, but subspans fit in so easy when you look at the code. DIV is as fast as 4px subspans. 4x4 tiles make no sense on this hardware.
So anyways, I want to do the perspecitve correction on real pixel positions -- so not exactly on the edge, but the first and last pixel.
Edge interpolation is not enough. For triangles I can invert a 2x2 matrix. This is also true for trapezoids if there were no rounding errors.
So each edge has to pick a pixel on the oposite side. Actually, I feel like if this is the result of clipping on the frustum, there is an obvious way for to get deltas along x or y or even both.
Then for the other we can save one mul, but still need the DIV. Ah the one common DIV. Anyway: for a trapezoid: pick the longer span ( top or bottom).
Bresenham on the edges allos me to use diffrent deltas for x U V W. One DIV per edge pales in contrast to the 3 DIVs per span that I need.
If there is memory left, small integer division could use a jump table. I need this for 1px long spans. For 2px I can use SBC instead of other instructions. For 4px shift. Both are 32 bit.
So basically only jump (every jump has a condition field) if power of two (2^0). Check: BSCAN, adq, SHL -> zero flag.

Since I only correct visible pixels, I need to do this for all edges of the polygon and those cutting in. Maybe I should select one horizontal delta value.
Just feels like I should go back for infinit precision raytracing maths for this one (ah, 32bit should be enough). Only triangles would short-cut to screen inverse matrix.
Should I just log the active edge list? In pass 1 I need to stop on each line with any change, but per polygon I just log changes within. Changes happen at a pixel.
So from the pixe I go to the left and search for left edges. Then I go to the right and search for right edges. Ah, thanks to clipping I can just choose the shorter side.
Each edge in this list has a link (8 bit ID, max 12 bit because 4096 polygons are beyond Jaguar Caps) to external memory. There is a link to the current position in the log.
Memory management needs a lot of linked lists. But the GPU cannot burst read items anyways. Just squeeze everything into 64 bit (reads).
Writes are queued in internal RAM and copied by the blitter. Changes in the active edge list are real vertices and crossings (some of it with the frustum).

An interesting number to profile would be the time spent on 32bit and float calcs.

Portal rendering. The beam tree leaves are convex polygons .. so portals.
I want to improve on Sky Hammer in the scenes where there is an enemy covering a lot of the screen or when I peek around a corner.
In both cases, portals help. Mostly I don't get the artwork in Skyhammer. All grey and almost no direction. I will need to generate some CRY textures with caching for shading.
When I find the overlap of two convex polygons, using a BSP tree is not the fastest way, although it may result in the smallest code size.
So we check the vertices of one polygon relative to the edges of the others. The order of the edges defines a BSP .. uh, but we don't split edges?
So what is the result: For each other vertex I see if they are inside of these edges. So it is a bit pattern. Does this help me? Some assembly trick? Did not work well last time.
What if I have both views?
Find cuts:  Number of cuts.
0 one inside one other ( all vertices inside all edges . Check from both sides.). Non-overlapping: Early out. Overlapping feels like collsion simulation and it is true. But I only deal with polygons with up to 4 vertices. 16 compares hurt, but I don't want to pull in separating axis theorem or CJK iterations and am not interested in contact points here. Maybe recheck later.
1 one.vertices, cut, other.vertices, cut

Crossing two vertices on the other side.
Does this work for the whole cone ? Check that camera is above polygon surface. Vertices of the polygon surface may be behind the camera. The latter test is the naive way to solve this. But it would need to chain divisions or at least rationals.
homogenous coordinates?
Other.Edge through face (vertices on both sides). Other.Edge . Volume = camera-Other.vertex  x   Other.edge x this edge  .. sign changes.
Early out vs collect signs first (branch free, optimized JRISC can be fast) and divide later. Okay, is probably not fast due to floats, but uh..
So on each polygon we get signs per vertex, and changes per edges. And we get links between edges. We get links because we check each edge with each other edge.
To justify this, in the outer loop we go over the polygon and calculate camera x edge. Then in the inner loop we inner product this with the corner rays from the camera.

The result is again a convex polygon. Calculate z. Sort. Ranges. Slope if deltaZ>2. X Ranges. Affine Slope for delta(round(X))>1.
The remaining space in the portal is not convex. But we now only need to cosider the visible edges and vertices.
The newly drawn polygon gets its central (longest) edge extended. Repeat recusively.
When drawing a triangle stripe/fan, the shared edge is extended. I don't want to pursue any heuristics into the third polygon.

How is the counting if we have a fully-in or fully-out early out? Like two convex polygons are fully inside the screen? I could try to profit from the code: Find the ovrerlap. Check z.
So we would allow up to two convex polygons in a leaf. When then another arrives, the old ones need to be converted into a BSP. Lazy BSP. If one polygon is fully inside leaf, but next is not: BSP!
Do I want 3 polygon inside checks? Maybe the new polygon is occluded? But I only get a probalistic answer. The new polygon may be fully inside the already drawn polygon, but behind.
So I want 3 inside relations? Or rather 6?

To allow a fast implementation of Elite, I should probably use the shiloutte of the ships as rough splitters, and then draw the polygon faces.
The nice thing compared to an indoor level is, that I can just sort by z on screen. Or maybe mix in apararent screen size ( space station, planet). Simple rule, easy to tune.

As a tree this would be kinda like a B-tree? So not binary. Each node divides the convex parent into one or two convex children, plus the rest.
Tree merge needs 4x4 comparisons. I really want this to happen while the blitter is occupied, but I don't see how.
How do I rasterize a half moon? It can have two spans per scanline. So I need to find the splitting vertex.
The floor line merging in Doom is a bit suspicous. I would understand mergin in DukeNukem3d with all the portals, but the Doom BSP has less splits, I think?
Anyway, in a true 6DoF I feel like "half moon" covered polygons happen a lot and the coordinate independent split feels weird. 90% of the speed of a full merged solution.
A complex polygon renderer can run parallel with the blitter. So we want complex leafs. Then we can calculate the next leaf (sort y), while we rasterize the current one.

Setting up the blitter is quite expensive.
So we want to draw as long lines as possible.
People don't complain about squares scrolling through.
Thus switching the directions ( x,y, both diagonales ) is okay.
Optimize to minimize scanlines and for minimal zchange ( hard limit on max z change)
Small triangles are drawn using affine transormation.
Quake and descent had scanline spans.
So when the scanline is really long, divide the rest in 16px or 8px spans.
In between, switch on perspective correction on the edges.
The top and bottom tip can stay affine.

Set up changes the least from line to line for affine mapping with subpixel correction ( we don't recalculate delta per scanline).

Color Ram can be used as texture cache because I don't plan to use palette in my artstyle anyway, but I need all GPU RAM for vertices. Or whatever, anyway,
Skyhammer showed that the small cache is best used when we draw quads.
The blitter can efficiently copy a rectangle from DRAM to color RAM. I mean, yeah: 2 cycle read, 1 cycle turn around,  4 cycles for write. But for a Jag this is fast, especially when we zoom in, or reuse tiles.
Again, the 8x8 quads on the output are beat. Just like on N64 the way to go is to split up a large polygon into a grid of quads. But similar to 3do we rely on this also for perspective correction.
I guess that recalculation of the gradient per scanline is faster than drawing two triangles. Maybe we can draw the top and bottom of the quad as triangles.

Also: Drawing direction can be choosen, for longer runs! And we can use rectangles for longer runs. Regarding the beam tree: Maybe we don't fuse leaf nodes if this busts the cache.
Quads don't dominate our geometry. We can still have Doom Mesas. We load rectangles based on the rays casted from the BeamTree leafs.
For small quads skinned onto a model it makes sense to to store them in a page. Though one page flip per 16px .. just read how many cycles each pixel needs right now. Ah, the blitter eats one cycle per line change and the page flip would eat two more.
This hardly justifies another code path. We don't cache on scale down!
Or at least we would only cache the output. But it does not help much as we have page misses all the time anyway.
The Jag has enough RAM so that we don't need tiles.

Squares are so attractive because they don't need the edge calculation.
The spans can be shorter and the GPU is still faster than the blitter.
Squares only make sense for large triangles.
Spans are as fast because divsion .. even though it inssist on 32 bit, only takes 18 cycles.
The blitter cannot do 4 px in 18 cycles.
Only if I try to do other stuff ( interupts ) while drawing the span, squares / rectangles would make sense.
As we all know there is no 64 bit texture source beside DRAM.
If we go for 50 fps, we could render to linebuffer .. do we go ?

For perspective on the edges ( const-z renderer like Doom ),
do I calculate exactly on the edge? Maybe for this precision thing?
Like I use 1/z and multiply(2 MAC) with the edge vector in texture space.
One division ( fixed point ) for linerp. So per line: 3 div, 4 mul.
2 Mul with fraction to go on the first pixel center.
Pro: Can be proven to stay in triangle. With low z variance we do affine anyway:
We can do multiple lines with one division for width and 2 Mul for subpixel.
Still seems faster than to calculate the diagonal.

Calculate on the first and last pixel: two div, 4 mul. integer div.
Bresenham to jump on pixel center. Adds for all 3 components of homogenous coordinates.
Pro: perspecitve closer to actual pixel. natural transition to affine.
Staying inside texture triangle can be forced by precsion on demand.

So I always calculate first and last pixel on the GPU,
but the blitter already for short spans allows me to write unaliged without RMW.
Maybe it makes sense to write up to 4 pixel into the source register ..
Todo: Test if 2n sourc register is shifted over without a read?
Still with 4 pixel like in Gouraud shading,
it might be interesting to fetch the texture using the GPU.
GPU master is 64 bit. DRAM is 64 bit.
eat dupAlicated phrase access, 
load
write into blitter
phrase mode
Still: A second code path? Lots of GPU cycles on short spans???
At least need to combine a short and a long span for this.
Oh, registers get crowded.
Or should I use the blitter to load the texture into GPU RAM?
Then use GPU to fill the phrase at the end of the line and blitter pixel mode for the 8 px spans.
No. Avoid all the storage.
Copy target has 2^n width.
GPU:
	2 add, 2 adc, move, shift, or, load, add light (saturate?unpack or high word + carry)   8 (4)
	(fraction."sign" xor destination.bit0) and shif 16 => shift_px and or  5
	saturated light is what makes the blitter the winner.
Gouraud is similar: needs <=4 GPU pixel. If saturation? Be sure to start on non-saturated side or from the middle.
	

To avoid divisions for short spans I thought about a lookup table.
Span length, subspan or 1/x lookup and MUL. MUL is faster of course. Oh my. Also less code.
Edges are expensive. So hide some of the calculation in a span?

If packing on GPU would not be so slow,
Then even the UV need the 16 bit shift.

n-gons help with long spans. Like Descent: If same skin and some tolerances (z, same face) are met.
I could even do scanline render for concave.
