Beamtree construction and even portals and rasterisation are kinda complicated.
I am not able to reason about code if vertices and edges don't line up.
I don't want the z-coordinate to dominate the render code. Pure direction (screen xy) only needs 16 bits.
And Jaguar has real 32 bit registers which lets me handle the product easily. Even some overflow bits to spare.
For the same reason, I'd rather not use NDCs ( rounding errors after re-scaling).
Instead I use a guardband with power of two field of view in each direction ( for square pixel 320x240 ).
A portal may have a smaller guard band. shifting and cmp works in 32 bit. So vertices with large z can be compared.
And I progably have some bits left to narrow down the field of view by SHL camera_space_xy .

Edges with both vertices within the guardband reference their vertices.
A clipped edge references one vertex and has a slope.
If both ends are clipped, it has an offset for the implicit function (0,0) needs to sit on a pixel, not screen center.
So pixel size goes into this calculation (nasty dependency).

Cuts between edges can be calculated at full precision because the denominator is a determinant and DIV accepts 32 bit quotients.
The thing is, we only get one coordinate per DIV because the mul trick would round.
This does not tell us if a edge is visible in a portal!
This is more meant for the rasteriser, which only needs y.

Level geometry needs not to be perfect. Additionally, polygons are not perfectly flat after rotation.
Backfaces are deterimined by the normal derived from the UV tangents.
A pragmatic solution is to let te for loop do its magic, and default to 0 iterations if the next y is not bigger.
We pick min and mix y for the loop starts, so everything will come full circle.
Edges are in sync with these vertices, so not special trick needed.

Subpixel precision is achived by solving the edge equation on each scanline. This goes like floor((8*16+32) / 16).
The quotient needs to be checked for zero beforehand. For loop should not have been enterred. Asser!
I feel like this is already so expensive that a sort_x can run async witht the DIVs. Or use abs() to create a min (uh no).
Just branch and cull the back-spans here ...
A third DIV for the increment for the blitter.

Of course for high triangles, we don't want to divide too much.
Bresenham needs us to divide the slope components to give integer steps. Then Mul,Add to maintain the control value.
Here again we need to check againtst 0 beforehand.
Division can be set into fixed-point mode. The (integer) result is shifted 16 bits to the left. 16 fraction bits are added.
With an edge going over the whole vertical screen distance, this really are only 8 fraction bits.
So we should try and use all bits we got and shift the dividend 8 bits to the left.
Now we need to check that the dividen componend is not bigger than screen_width*divisor (instead of zero).
In this case, the edge can only cover one y scanline. No need for a slope. Assert!
With all the small triangles in Iron Soldier, I guess that the Bresenham is not only cleaner, but also faster.

So, the remaining question: How to cut (with an edge ) through a polygon?

Let's look at a vertex (pixel) with two edges (16 bit fraction implicit slopw).
The cut would also be an edge of same precision. We get then calculate the two cut pixels. 
We can compare slopes and these with the corner vertex to check if the cut pixels are on the polygon edge or just on the line somewhere else.
Indeed we need to check one more pixel-vertex of the polygon to see if the cut hit us.
So how do we do this efficently?
The implicit function of the cut can be calculated easily. Do it on all pixels and all their corners?
Then we know which cuts with the edges are even interesting. We only need pixel cuts here, too. So there will be a final integer division.
But before that, we need 32 bit math. Two implicit equations are like coords * 2x2Matrix16 = 2x2 bias32.
To get the coords, we need to invert the MAtrix. For this we need to 
- calcualte the determinant: 16x16 = 32 . Good!
- Multiply bias32 * other_transpose(Matrix) .  Oh 32 bit math. Bad. Don't do too often!
So even though we only want a pixel, before the DIV we need full 32 bit.
This is integer div, so we only need to check against zero beforehand. And afterwards check against visible screen generally before adding a fraction(for what ?), but specificaly here: Check against the vertex pixels to cull.
I feel like I keep division unit in integer mode for edges? Ah, only once per edge start. I could even use SAR to cut off bits later. Uh, but then need to check for overflow. Store slopes in edges before rasterisation?
I feel like perspecitve correction for texture and with it the z value need to be fixed point throughout.

When I float the slope anyway, why use fractions? I use floats for clipped edges. I need fractions if both endpoints are on screen to securely meet them. I cannot adjust a vertex because it ends multiple edges,
but I can adjust the cut pixel with the screen. And I could check the rounding of the slope. So I check the reminder ( which is a bit difficult, but I need to affect flags anyway)
If not zero, the quotient can be in ther interval of the lsb. I know the end vertices. For float slope I need to store x fractions in one of the vertices.
Now with the given quotient, I can calculate x fixed point on the other pixel. Actually, I use the DMZ inbetween the pixels usually.
So for float, I don't use the center of the DMZ, but top-left pixel. So I get x on all y for rasterization.
To have a good feeling while doing cuts, I want to hit DMZs. So on the reciever side of the other DMZ, I calculate x.
I could try manipulate the startx, but why not stick to the quotient at hand and try out floor and ceil. With the given precisions, one of these should hit the receiving side (along x) of the DMZ square. Easy.
Divide by zero should look like overflow ( DIV is unsigned ). It gives us a slope which is wider than our screen. No rounding done here, just limit to the pixels far side.

Jaguar address generator has 10.16 precision. This matchens fixed point DIV quite well. Just this makes me want to use 32bit math for textures. The rasterizer always multiplies with 8 bit, so it is not so expensive.
Along long edges I need on MUL to calculate the delta. One Add for the other Delta.
Full math ( 16 bit mantissa float might not be good enough for flying low on repeated flow texture ) might need 32x32, but is only done once per polygon.
Perhaps have 3 render paths: very low delta-z : affine. Medium delta-z: floats. Large delta-z: 32 bit.

Also it looks like I should not use full 16bit for coords. Even if I center 0,0 roughly, deltas will be 16+1 bit.
MAC needs another bit. So effectively within the guardband, projected screen coords are 14:14 .

old version:
The simple case is that we get cuts on fresh pixels (on an existing edge, but between its end x or y depending on direction).
The vertices of the polygon can be [16,16]. Then just apply this position onto the implicit edge function.
But what if the vertex of the polygon is a cut?
Then we know that we only need this for rasterisation, and constraint our evaluation into the box spanned by the (up to 4) pixels positions.
Ah, if the fresh pixels are inside this box, we are done. When neither edge crosses a scanline, we are done. Actually, same for vertical lines.
So we have a rectangle (box) with pixels in opposing corners. Implicit functions are easy to evaluate. We could evaluate at the inwards points.
We know that all cuts are within the pixels. So the inside / outside relation is uniform along the edge crossing the rectangle.
So if one edge is more inside ( relative to polygon ) as evaluated at the inwards ( relative to rectangle ) point, this edge wins.
If both edges exit both pixels on the same side, we at least now have a one dimensional problem.
We have each  values at the corner + (x or y) * slope_(x_y) ) =0
<=> (x or y)  =  values at the corner / slope_(x_y) 
compare = subtract 
discriminator = value_a at the corner * slope_ b - value_b at the corner * slope_ a // so  this is 32*16

Now we could think with 32bit we should just use full 3d values with some less rounding, but after some investigaton: dead end.
So, this is not pure. Another synergy would be to allow more than two edges per sanline (also for non-monotonous y). Then bubble-sort by x. Backface determined by normal beforehand.


z values similar to the texturemapping don't influence loops and algorithms. A call to the z-function gives me a bolean once in a while. Sort-independet translucency would work without.
Nonetheless, z calcuations are a big burden on JRISC because they do need 32x16 or worse.
z cuts ( diving into water) send a screen edge ( floated [16,16] slope + offset ) to the beam tree. This is clearly more expensive and should be optional.
I need to catch bugs when the horizon enters the polygon. The texture will also jump around. I am broken now, but originally wanted perfect guards within the texture atlas.
Now I can optionally ( beause costly ) check that UV coords are inside a polygon (with rounding) before transmitting them to the blitter.







So it looks like that sub-pixel precision edges live within constraints given by pixel precise 2px wide edges. Beam construction might be different, but the rasterizer works this way.
This means that I have to calculate edges twice.
Rounding errors do make the polygons non-convex. I don't care in x direction, but very much in y. The effect is small below epsilon, but might trigger the need to consider more than two edges within a scanline.

So the parallel instead of sequentiel information flow is really only for repeated cuts. Anything 1. Frustum, 2. Portal : the portal cut starts from the same coeeficients. Same for z,u,v .
For N64 with floats there is no problem with the cascade (pure fixed point, no need for floor()), but on JRISC (and even PS1) there may be a visible difference in glitch density. 
Beam trees ( and even portal renderers) would apply multiple cuts. John Carmack went for zero glitches in Doom, IMHO. I don't want large levels to become glitchy, only slow.
Same rendering engine should be useful for stills.




Perspective correction is slower than affine texturemapping because I need to also fill the increment register.
I may need to check the SDK code, but please, don't change horizontal increment for affine triangles.
Small area triangles need to be affine. Slithers are extremely slow with correction. Also check z-dynamic to apply this render path on as much triangles as possible.
Reuse of the increment is also a reason why pure scanline rendering is a bad idea for texture mapping, less for Gouraud, but certainly for SRCshaded textures as in skyhammer.
JRISC lacks certain instructions to efficiently fill the texture registers. Nothing is faster than naive:

;increment along edge and fight the slow branches in JRISC
add r10,11 ; eigentlich: check sign of r10 ? That would mean the loop depends o
branch on carry ;to select delta. Bresenham creates two different deltas
;perspective add w first position  for in-loop DIV
;perspecitve div w
add r1,r8	; s
add r2,r9	; t 
add r13,r14 ; x  nur integer

When I keep increments in the blitter register, uh, I save two registers on the GPU. So how many do I need?
(s,t,(xy,counter) =4) * (alternative jumps=2 + akkumulator=1  =3 ) = 12  

;interleave words -- okay ist jetzt nicht so viel komplizierter als der doppelt Bresenham
interleave instructions{
cp r1,r2
cp r2,r3 ; could swap these two. Would not make much of a difference, but
and 10,r3 ; Maybe I can deliver r3 to or ? But there is alredy shift quick for this.
|
cp r4,r5
cp r5,r6
and 01,r6
}
;perspective: can place one mul,mul,DIV  here. ; DIVs in my code do not depend on each other (LINERP uses lookup). So the DIV bug does not apply. Even the LINERP does not depend directly on perspective. SUB acts as fence. 
interleave {
shift r5
or r3,r5
-- uh, wait for blitter?  load 02238; btest 0
store -- interleave is mandatory to reduce blitter idle time. Maybe MoveTa instead of store, then flip page (all others are off the score board because reg-reg calcs only), then store, then flip back.
|
shift r2
or r2,r6
store displacement
}


Bresenham needs two decisions which I want to implement as up jumps to eliminate the loop jumps. Taking a jump costs 3 cycles;
and additionally there may be wait states to deduce the condition (though it looks well with all the numbers I have to crunch anyways).
Slight loop unrolling is justified I think, just I would love to have all of the scratchpad memory for me here.
So only full trapezes get this fast treatment, after I don't need any scanline rendering anymore. Also beam tree cannot trigger these, I guess.
I have the feeling that beam tree code will be too big anyway. Yeah sorry, no parralel GPU, blitter execution.
Maybe self modify code? Affine texture mapping gets unrolling, while perspecitve gets W ordinate.
Both edge increments are round half up. So I know the favourable code path

loop{
other left
favour right
block optional break if counter  also jump in here. This allows me to duplicate code before and after this loop to have special cases for first and last. Espciallly, bresenham is needed one less than lines of polygon
favour left
other right
}counter was already elsewhere

So all combos only need one jump, , but other right, other left . Code duplication lets us reduce these 3 jumps to 2.

store F0220C ; screen position. A2 Okay, here I am glad that it is only a single register. X is low word. For 3 direction const-z, the code is not allowed to care.
store F0223C ; counter . For max speed I could detect changes

We have enough registers. Any ROR, NOT will save a register, but cost a cycle. Same with double shift.
Now when does perspecitve come into play?
13*2=26 cycles just for storing values is as long as a division. The edge calcuations take as long. MUL is not async to it has to be added.
So basically we can say that the two DIVs on both edges are not the bottleneck .. if I can spread them equally.
There would be multiple scanlines in flight.
Uh, this is too expensive. Rather I need to start one DIV right when the left edge was calculated and one after the interleave for the left edge was done. Oh this does not sound efficient.
So rather have more of an unrolled loop? I don't want to duplicate Bresenham. So I only have the special first lopp and last . I don't see how I can put ping-pong registers in the Bresenham construct.
At least I don't really have space.
So I use the interleaved start register as delay stage. Looks like I need a duplicate of xy . Ah, but perspectiv correction already as uvw as inputs and st as output.
So for the left edge I have all different registers. I need to delay the right edge u,v. 
Loop is enterred before the blitter call and abort condition is after wards. so blitter is called one more than bresenham.
To fill the delayed registers I would need to calculate the first line before the loop.
This does not work. Rather I enter the loop after the blitter because then  .. the question is: what code do I duplicate
expensive computer with uvw -> st or expensive IO towards the blitter.
Raterh I need to computer before the loop. Loop has as many block encounters as scanline. Also need to call the blitter as often. But Bresenham is one less. So enter before blitter, break after.
Or I call the blitter afterwards. Loop iterations are the same, but I enter after Bresenham because delay registers are not yet valid. Then break after blitter, access delayed calculations (LINERP) and blitter.
# UVW and edges -> DIV, second data interleaving , wait for blitter
# process DIV result, kick off other DIV, first interleave -> TA, linerp via lookup, mul 

Quake has special cases for linerp. I want fast corners

load base+delta_x, target
compq deltax, 3
;interleave : perspective MUL U,s; latest position to access DIV result in loop
if smaller then jump target    ; if there were not so many funny rules around jump, I could put two jumps butt to butt ... Bresenham already does the up jumps. I want to reuse code verbatim for perspective
	;delay slot : perspective MUL v,t
	x_end=x_start : do nothing
	delta_x=1 : set xy integer
	delta_x=2 : set integer for akku and increment  .. so not in all cases. Use addressing mode with offset

default (no jump?) : It is a shift. How do I detect those without jumping? 
bitscan
add silly_bias,s
shift s,delta_x
if zero flag
{
	shiftR s,increment
}
else
{
	setup{cp buffer_address_in_localSRAM}
	add delta_x
	and wrap_around   ; rem ODer page aligned und einfach mit bset das carry killen. Also die addresse muss mit 0 enden. Sonst muss man auf sub umstellen. Also delta_X signed? Aber bitclear statt bitset ist ein anderer opcoce!
	58 LOAD (R14+Rn),RM 
	for x,y{
		cp increment32
		mul divisor,increment32   .. uh 
		shR increment,16 ; Maybe here is some synergy with interleave

		ror increment32_cp
		mul divisor, increment32_cp		
		add increment32_s
	}
}
store integer.fraction 

Selection of const_z seeems like a realy good idea. Even though the subspans use fast shift_R, I think we need even more registers and additional code. And I want extra long blitter runs.
Of course, 3 direction drawing is incompatible with scanline-rendering.
Scanline rendering access the bus. Hmm, could try to do it when I will be waiting on the blitter in a minute anyways.
Per polygon render may load the affine or corrected code (self modify).
I should not correct corners even of otherwise corrected poygons. I just akzept some skew on the border (histeresis: as polygon grows in animation, and or const-z gets unfavouralbe: correct belt bursts open).
Occlusion may still leave large parts of unoccluded poylgons where the edge calculation can go vroom.
To use the full 32 bit precsion of the blitter address generator, I set up every triangle with full precision, but the scanline renderer then also needs to jump using 32bit mul.
I don't know how to efficiently trigger deltas from occluding poylgons.
Of course, I do frustum (special code path with less or no Bresenham?).
The deltas for the edge are a speed advantage when I can use them for at least like 8 lines. Does not matter if due to occlusion or own edge.
I only know this after the scanline reneder has looked ahead of beam tree was used. The scanline renderer on any vertex would trigger the rendering of the lines upwards. But I want const-z !
Some overdraw might be okay after all? Ah, I guess that I want to die on this hill. See: Quake2 span buffer. Large background polygons read from the span buffer / visiplanes.
I would need to correct every span. I would need meta information to detect edges (over 8 lines) and corners which better are renderered using affine mapping.

So with about 64 cycles per line, the blitter can blit 8px in pixel mode without fast-page mode. Ah wait read to write cost another cycles. So 9*8=72 cycles per scanline.
So let's say that blitter and GPU are matched on average because a lot of triangles in Fight4Life or BattleSphere are about 16px wide.
It might be tempting to have a queue over the height of a trapezoid. In contrast to interleave of long and short spans, here I can pay back on triangle set-up. And code is clear because the queue is separate and dumb. Draw middle vertex to coners

wait:
if blitter idle then shortcut ; 'Blitter does no care about order of lines
else ;shelve
cmp write_pointer, wrap_around  (or test?)
	== goto wait
	<> store [write_ppointer++& wrap]

: ;second place in GPU loop and later on triangle set-up to pay back the shelved blitter runs.
cmp read_pointer, write_pointer
if <> and blitter_is_idle then load[read++& wrap],store in blitter

ADQ
AND
Load					xy
;these const two more cycles per instruction. This is a clear disadvantage of the queue and shows the need for the short-cut
;going throuhg the queue word by word adds 3 instructions into our tight memory and only removes 3 cycles?
load displacement		st
load displacement		fraction
load displacement		counter
store
store displacemnt only costs one cycle per instruction. Oh, register loads happen on different cycles anyway. 
Shortcut uses the same blitter registers, so maybe have their addresses in different registers? I don't think that I have much left


Scanline-Renderer: Cons: I cannot do const-z texture mapping and 8x8 tiles is hard.
For interpolating values, this is not really so bad because Jaguar has faster MUL than branch.
So I could hit two edge pixels out of the blue, load a whole matrix to multiply (x,y)&Matrix+Offset -> s,t,lumen. Or uvw . And edge propagation data.
The nice thing is that shared edges are calculated only once and the branch in Bresenham does not bother me as much (or the cumbersome branchless coding which all relies and ADC).
Even for individual polygons it seems to be faster to use x_start and x_end in MUL to get UVW. Like, add fixed point. Always keep the UVW start values (uh that costs).
Hmm, weird. This seems to be worse than ADD->Add 0 carry -> mul  or even Add -> adc -1 -> AND, ADD for 32 bit.
MUL has no problem with occlusins, while ADD would need new intialisation on every edge cutting in. To use the 32 bits, the initialisation needs slow 32 bit MUL.
This makes z-sort interesting again. Draw full polygons and only cut out others which don't match the order.
My problem is that z-sort eats into the processing time for only a small benefit here. I hate the tuning hacks like buckets or Qsort.
Without buckets, sorting will be almost perfect. I would use occlusion information only to determine the visible scanlines, but still propagate along the edges?
Maybe I find occluding edges which still keep the edge count at 3 or below? Like The frustum with its free edges.
Portal rendering accepts 6 edges. I guess that edges created by small debris flying in front of a house can give quite the spikes in render time.
I cannot render scanlines and then draw all intakt polygons because then the eventless scanline would be wasted.
Or at least, I could defer rendering, and then on the first occlusion, I render the polygon up to the scanline and switch to scanline rendering there in order not to need to save massive amounts of temporary data.
Just because on typical games, 80% of the polygons seem to be intakt. Of course I would love a symmetric approach.

Only beam trees scale in a sane way. I would use a stack and manage the overflow in natural way. No oppionated hack to repeat code in registers, SRAM, DRAM.
With scanline rendering on the other hand I know how many edges I have. I reserve an active edge list of the same size in DRAM. This list is short compared to DRAM size.
LoadP is a fast way to crawl through the edges. I only need to write back indices occasionally. So, all this drawing data is kept at the edges. Only the indices are sorted so that I don't need StoreP.
Problem is: Active Edge list is as uncool as z-buffer. The hardware should have done that efficiently. Why do I need to write software for it?

At least with pure scanline algorithm I probably have something to draw every scanline and it does not hurt that skipping lines is kinda difficult.
Actually, the concurrency with the blitter is far better here. Base address and shading are only two values which switch between faces.
All the other values switch even within a polygon: s,t,x,y,luminosity.
With blitter control and visible surface determination both in code cache, we can releax and not try to cache any data or do blitter double pass.


Of course, Doom had a boudning volume hierarchy. Beam trees are compatible, but scanlines are also. Feed the bounding surface into the algorithm.
When it tries to draw the first pixel, bait and switch, replace the bounding volume with the detailed interiour. Same for portals.

So it seems like there is no hybrid between scanline rendering and painters. At least I get scary worst case (memory scenario).
Now I am almost sure that I don't have enough code memory to squeeze in scanline rendering (16 bit math, 32 bit math) and texture mapping (texture coordinates at corner, sub-spans, register address)
at the same time. Maybe I even want shading because Fight4Life looks so flat.
I can define a happy path. Polygons with max vertices. Like obviously we need at least 3. 4 happens due do clipping (on frustum) or occlusion. 5 can also happen.
Convex. The rasterize needs to deal with non-convex polygons. Ah wait, that is ugly along the edges. I can only store two edges in the registers.
So, mostly convex. And where was I : Indices to at least 5 vertices .. make that 8.

So it can happen that we cannot write out the complete polygon. To make the sub-span renderer happy, there needs to be a winner on merge and a default on split.
So the effect is like this: Many small polygons in front of one large ( biped in front of a wall ), fills up my memory with lots of "virtual" polygons to draw "around" the characters.
Lets just say I accept as many (additional) virtual polygons as real ones (256+256) and hence have limit for the memory usage.

Z-sort may be a way to avoid this, but is not without hassle. So obviously I have determined which polygons are in front.
Ah, all the large "background" polygons need to be resolved within. Likewise the small polygons should be resovled within their group because most results are easy to process.
The BeamTree is looming in the background because the active edges list needs fast inserts, which needs a tree.
A hybrid solution would be two fold. I check all edges for the next crossing and may skip some lines completely. This is kinda a test from the BeamTree.
Then when the number of edges gets two big for local memory and brute force memcpy, a visble edge is chosen to split left / right.

Polygons may be split onto both sides. So I later may want to fuse them. By using a real edge instead of vertical (from a vertex) or blocks,
I at least safe one polygon from a split. Now this edge may even belong to two poylgons, or it is an edge of an object and occludes stuff behing it : So many cases without polygon splits!
It is still a bit ugly that I want to keep code around to check.

I thought about the span buffer Quake is said to have. It fits the blitter. With a low resolution I might write span starts at pixel positions.
The blitter can clean this buffer. Even if this solves allocation, I still need pointers to jump over other polygons and to advance into the next scanline, heck, even for overdraw.
This becomes a deferred renderer: Draw everything flat shaded with z-buffer. Use blitter (pixel mode) to find span length.
GPU calculates texture coordinates for start and end. Use blitter (pixel mode) to fill span. Interleave this to keep blitter and GPU occupied.
Like for one blitter action the GPU does the left pixel and for the other the gpu does the right pixel.
The backbuffer is for the first part. If I don't mind screen tearing, the second pass renders to the 16bpp front buffer. I hope that Grouraud shading code paths also fits into local memory.
"It normally compares the source data register with the pattern data register," => "The action of the Blitter can be stopped altogether"

After clipping, affine texture mapping does not work anymore. I guess that the KISS method is to clip perfectly, but then interpolate on the edges.
I do not like that I need one extra division per scanline to recalculate the delta. Divisions should be used for perspective correction..
uh but which also needs one delta calcuation per scanline. Triangulation would indeed avoid this. But then again, I have one division free per scanline iteration.
Guard band for very small affine triangles. A nodge towards perspecitve correction for larger. Maybe have an executable with either code path / or a quality option?

Sorting (by y) is so incredible fast that I want to start with scanline rendering for the visibility determination, but defer the rasterizer due to code cache size.
Memory managemnt is like: count number of vertices for each y "bucket". Then fill in the vertex IDs. Bucket sort.
Even packing in internal memory would be possible. load ror add rol (either counter or increment) store.
Quicksort and Mergesort are also good conentenders, but have weird worst cases when I take internal memory constraints into account.
Finally, for cockpit view with like 120 lines on screen, bucket sort just plain wins.

Scanline rendering is only fun with bubble sort. Edges cross on screen, and exhchange places in RAM. No suprises. I feel like this can be made very fast.
Use the blitter to load a chunk. Ah, probably want to completely sort it? Write back all but the values moved to the top end. These are now the low end in the next block.
CPU moves back and forth in the cached block. Then blitter goes back and forth over the blocks. Maybe there is a way to verify order early? Note when ends are sorted?
So only bubbles would let the sorter move into these region.

Active edge list can be a b-tree with root in internal memory and leafs in external memory.

Z-resolution pulls in float too often. So we reduce its count. First only for xy overlap (perfect). Then check for z exp, then z mantissa, then cut line projected on screen (32 bit probably).

I determine visible surfaces in a separate pass for profiling. But is a bit difficult to destill the clipping information. I seems like I need to repeat the active edge list stuff in the next pass.

Small triangles use the affine rasterizer. I use the guard band to allow (small) triangles to use this fast pass independently from some rather arbitrary clip. Or do I? Whan about occlusion?
Maybe I should not play tricks. Affine is only for unclipped, unobscured, small area*delta_z triangles.
Anything larger uses edge interpolatation and then span interpolation. So actually, I want to correct perspective on the edge if I have to interpolate the span anyway.
For larger triangles add subspans. I know I loved tiles, but subspans fit in so easy when you look at the code. DIV is as fast as 4px subspans. 4x4 tiles make no sense on this hardware.
So anyways, I want to do the perspecitve correction on real pixel positions -- so not exactly on the edge, but the first and last pixel.
Edge interpolation is not enough. For triangles I can invert a 2x2 matrix. This is also true for trapezoids if there were no rounding errors.
So each edge has to pick a pixel on the oposite side. Actually, I feel like if this is the result of clipping on the frustum, there is an obvious way for to get deltas along x or y or even both.
Then for the other we can save one mul, but still need the DIV. Ah the one common DIV. Anyway: for a trapezoid: pick the longer span ( top or bottom).
Bresenham on the edges allos me to use diffrent deltas for x U V W. One DIV per edge pales in contrast to the 3 DIVs per span that I need.
If there is memory left, small integer division could use a jump table. I need this for 1px long spans. For 2px I can use SBC instead of other instructions. For 4px shift. Both are 32 bit.
So basically only jump (every jump has a condition field) if power of two (2^0). Check: BSCAN, adq, SHL -> zero flag.

Since I only correct visible pixels, I need to do this for all edges of the polygon and those cutting in. Maybe I should select one horizontal delta value.
Just feels like I should go back for infinit precision raytracing maths for this one (ah, 32bit should be enough). Only triangles would short-cut to screen inverse matrix.
Should I just log the active edge list? In pass 1 I need to stop on each line with any change, but per polygon I just log changes within. Changes happen at a pixel.
So from the pixe I go to the left and search for left edges. Then I go to the right and search for right edges. Ah, thanks to clipping I can just choose the shorter side.
Each edge in this list has a link (8 bit ID, max 12 bit because 4096 polygons are beyond Jaguar Caps) to external memory. There is a link to the current position in the log.
Memory management needs a lot of linked lists. But the GPU cannot burst read items anyways. Just squeeze everything into 64 bit (reads).
Writes are queued in internal RAM and copied by the blitter. Changes in the active edge list are real vertices and crossings (some of it with the frustum).

An interesting number to profile would be the time spent on 32bit and float calcs.

Portal rendering. The beam tree leaves are convex polygons .. so portals.
I want to improve on Sky Hammer in the scenes where there is an enemy covering a lot of the screen or when I peek around a corner.
In both cases, portals help. Mostly I don't get the artwork in Skyhammer. All grey and almost no direction. I will need to generate some CRY textures with caching for shading.
When I find the overlap of two convex polygons, using a BSP tree is not the fastest way, although it may result in the smallest code size.
So we check the vertices of one polygon relative to the edges of the others. The order of the edges defines a BSP .. uh, but we don't split edges?
So what is the result: For each other vertex I see if they are inside of these edges. So it is a bit pattern. Does this help me? Some assembly trick? Did not work well last time.
What if I have both views?
Find cuts:  Number of cuts.
0 one inside one other ( all vertices inside all edges . Check from both sides.). Non-overlapping: Early out. Overlapping feels like collsion simulation and it is true. But I only deal with polygons with up to 4 vertices. 16 compares hurt, but I don't want to pull in separating axis theorem or CJK iterations and am not interested in contact points here. Maybe recheck later.
1 one.vertices, cut, other.vertices, cut

Crossing two vertices on the other side.
Does this work for the whole cone ? Check that camera is above polygon surface. Vertices of the polygon surface may be behind the camera. The latter test is the naive way to solve this. But it would need to chain divisions or at least rationals.
homogenous coordinates?
Other.Edge through face (vertices on both sides). Other.Edge . Volume = camera-Other.vertex  x   Other.edge x this edge  .. sign changes.
Early out vs collect signs first (branch free, optimized JRISC can be fast) and divide later. Okay, is probably not fast due to floats, but uh..
So on each polygon we get signs per vertex, and changes per edges. And we get links between edges. We get links because we check each edge with each other edge.
To justify this, in the outer loop we go over the polygon and calculate camera x edge. Then in the inner loop we inner product this with the corner rays from the camera.

I need quite a few values I also would need for perspective correct testure mapping. I mean, I need 32 bit W values.
Scanline rendering would need to sub-pixel correct as we reach the scanline of the top vertex. With other vertices know I need to calculate delta.
Going to the next scanline, vertical delta is applied .. Bresenham the whole package. Then on the scanline horizontal delta is used to propagate to the edge which may occlude our polygon.
I am kinda back at the 32bit z-buffer of the blitter. 

The result is again a convex polygon. Calculate z. Sort. Ranges. Slope if deltaZ>2. X Ranges. Affine Slope for delta(round(X))>1.
The remaining space in the portal is not convex. But we now only need to cosider the visible edges and vertices.
The newly drawn polygon gets its central (longest) edge extended. Repeat recusively.
When drawing a triangle stripe/fan, the shared edge is extended. I don't want to pursue any heuristics into the third polygon.

How is the counting if we have a fully-in or fully-out early out? Like two convex polygons are fully inside the screen? I could try to profit from the code: Find the ovrerlap. Check z.
So we would allow up to two convex polygons in a leaf. When then another arrives, the old ones need to be converted into a BSP. Lazy BSP. If one polygon is fully inside leaf, but next is not: BSP!
Do I want 3 polygon inside checks? Maybe the new polygon is occluded? But I only get a probalistic answer. The new polygon may be fully inside the already drawn polygon, but behind.
So I want 3 inside relations? Or rather 6?

To allow a fast implementation of Elite, I should probably use the shiloutte of the ships as rough splitters, and then draw the polygon faces.
The nice thing compared to an indoor level is, that I can just sort by z on screen. Or maybe mix in apararent screen size ( space station, planet). Simple rule, easy to tune.

As a tree this would be kinda like a B-tree? So not binary. Each node divides the convex parent into one or two convex children, plus the rest.
Tree merge needs 4x4 comparisons. I really want this to happen while the blitter is occupied, but I don't see how.
How do I rasterize a half moon? It can have two spans per scanline. So I need to find the splitting vertex.
The floor line merging in Doom is a bit suspicous. I would understand mergin in DukeNukem3d with all the portals, but the Doom BSP has less splits, I think?
Anyway, in a true 6DoF I feel like "half moon" covered polygons happen a lot and the coordinate independent split feels weird. 90% of the speed of a full merged solution.
A complex polygon renderer can run parallel with the blitter. So we want complex leafs. Then we can calculate the next leaf (sort y), while we rasterize the current one.

Setting up the blitter is quite expensive.
So we want to draw as long lines as possible.
People don't complain about squares scrolling through.
Thus switching the directions ( x,y, both diagonales ) is okay.
Optimize to minimize scanlines and for minimal zchange ( hard limit on max z change)
Small triangles are drawn using affine transormation.
Quake and descent had scanline spans.
So when the scanline is really long, divide the rest in 16px or 8px spans.
In between, switch on perspective correction on the edges.
The top and bottom tip can stay affine.

Set up changes the least from line to line for affine mapping with subpixel correction ( we don't recalculate delta per scanline).

Color Ram can be used as texture cache because I don't plan to use palette in my artstyle anyway, but I need all GPU RAM for vertices. Or whatever, anyway,
Skyhammer showed that the small cache is best used when we draw quads.
The blitter can efficiently copy a rectangle from DRAM to color RAM. I mean, yeah: 2 cycle read, 1 cycle turn around,  4 cycles for write. But for a Jag this is fast, especially when we zoom in, or reuse tiles.
Again, the 8x8 quads on the output are beat. Just like on N64 the way to go is to split up a large polygon into a grid of quads. But similar to 3do we rely on this also for perspective correction.
I guess that recalculation of the gradient per scanline is faster than drawing two triangles. Maybe we can draw the top and bottom of the quad as triangles.

Also: Drawing direction can be choosen, for longer runs! And we can use rectangles for longer runs. Regarding the beam tree: Maybe we don't fuse leaf nodes if this busts the cache.
Quads don't dominate our geometry. We can still have Doom Mesas. We load rectangles based on the rays casted from the BeamTree leafs.
For small quads skinned onto a model it makes sense to to store them in a page. Though one page flip per 16px .. just read how many cycles each pixel needs right now. Ah, the blitter eats one cycle per line change and the page flip would eat two more.
This hardly justifies another code path. We don't cache on scale down!
Or at least we would only cache the output. But it does not help much as we have page misses all the time anyway.
The Jag has enough RAM so that we don't need tiles.

Squares are so attractive because they don't need the edge calculation.
The spans can be shorter and the GPU is still faster than the blitter.
Squares only make sense for large triangles.
Spans are as fast because divsion .. even though it inssist on 32 bit, only takes 18 cycles.
The blitter cannot do 4 px in 18 cycles.
Only if I try to do other stuff ( interupts ) while drawing the span, squares / rectangles would make sense.
As we all know there is no 64 bit texture source beside DRAM.
If we go for 50 fps, we could render to linebuffer .. do we go ?

For perspective on the edges ( const-z renderer like Doom ),
do I calculate exactly on the edge? Maybe for this precision thing?
Like I use 1/z and multiply(2 MAC) with the edge vector in texture space.
One division ( fixed point ) for linerp. So per line: 3 div, 4 mul.
2 Mul with fraction to go on the first pixel center.
Pro: Can be proven to stay in triangle. With low z variance we do affine anyway:
We can do multiple lines with one division for width and 2 Mul for subpixel.
Still seems faster than to calculate the diagonal.

Calculate on the first and last pixel: two div, 4 mul. integer div.
Bresenham to jump on pixel center. Adds for all 3 components of homogenous coordinates.
Pro: perspecitve closer to actual pixel. natural transition to affine.
Staying inside texture triangle can be forced by precsion on demand.

So I always calculate first and last pixel on the GPU,
but the blitter already for short spans allows me to write unaliged without RMW.
Maybe it makes sense to write up to 4 pixel into the source register ..
Todo: Test if 2n sourc register is shifted over without a read?
Still with 4 pixel like in Gouraud shading,
it might be interesting to fetch the texture using the GPU.
GPU master is 64 bit. DRAM is 64 bit.
eat dupAlicated phrase access, 
load
write into blitter
phrase mode
Still: A second code path? Lots of GPU cycles on short spans???
At least need to combine a short and a long span for this.
Oh, registers get crowded.
Or should I use the blitter to load the texture into GPU RAM?
Then use GPU to fill the phrase at the end of the line and blitter pixel mode for the 8 px spans.
No. Avoid all the storage.
Copy target has 2^n width.
GPU:
	2 add, 2 adc, move, shift, or, load, add light (saturate?unpack or high word + carry)   8 (4)
	(fraction."sign" xor destination.bit0) and shif 16 => shift_px and or  5
	saturated light is what makes the blitter the winner.
Gouraud is similar: needs <=4 GPU pixel. If saturation? Be sure to start on non-saturated side or from the middle.
	

To avoid divisions for short spans I thought about a lookup table.
Span length, subspan or 1/x lookup and MUL. MUL is faster of course. Oh my. Also less code.
Edges are expensive. So hide some of the calculation in a span?

If packing on GPU would not be so slow,
Then even the UV need the 16 bit shift.

n-gons help with long spans. Like Descent: If same skin and some tolerances (z, same face) are met.
I could even do scanline render for concave.
